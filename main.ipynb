{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3135c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from nilearn import plotting\n",
    "from nilearn.image import resample_to_img\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse import csgraph\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.ticker as mticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil, os\n",
    "p = psutil.Process(os.getpid())\n",
    "p.cpu_affinity({0,1,2,3,4})   # use only core 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b8b86",
   "metadata": {},
   "source": [
    "Loading Datasets and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = 1\n",
    "sub = '04'\n",
    "run = 1\n",
    "\n",
    "base_path = '/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives'\n",
    "anat_img = nib.load(f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain.nii.gz')\n",
    "\n",
    "data_name = f'sub-pd0{sub}_ses-{ses}_run-{run}_task-mv_bold_corrected_smoothed_reg.nii.gz'\n",
    "BOLD_path_org = join(base_path, f'sub-pd0{sub}', f'ses-{ses}', 'func', data_name)\n",
    "bold_img = nib.load(BOLD_path_org)\n",
    "bold_data = bold_img.get_fdata()\n",
    "bold_data = bold_data.astype(np.float16)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_mask.nii.gz'\n",
    "back_mask = nib.load(mask_path)\n",
    "back_mask = back_mask.get_fdata()\n",
    "back_mask = back_mask.astype(np.float16)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_0.nii.gz'\n",
    "csf_mask = nib.load(mask_path)\n",
    "csf_mask = csf_mask.get_fdata()\n",
    "csf_mask = csf_mask.astype(np.float16)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_1.nii.gz'\n",
    "white_mask = nib.load(mask_path)\n",
    "white_mask = white_mask.get_fdata()\n",
    "white_mask = white_mask.astype(np.float16)\n",
    "\n",
    "print(anat_img.shape)\n",
    "# print(bold_data.shape)\n",
    "# print(back_mask.shape)\n",
    "# print(csf_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6a96e",
   "metadata": {},
   "source": [
    "Apply Masks on Bold Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec92f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_mask_data = back_mask > 0\n",
    "csf_mask_data = csf_mask > 0\n",
    "white_mask_data = white_mask > 0.5\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "nonzero_mask = np.where(mask)\n",
    "\n",
    "white_mask_flat = white_mask_data[nonzero_mask]\n",
    "keep_voxels = ~white_mask_flat\n",
    "\n",
    "bold_flat = bold_data[nonzero_mask]\n",
    "masked_bold = bold_flat[keep_voxels]\n",
    "\n",
    "print(f\"number of selected voxels after masking: {masked_bold.shape[0]/math.prod(bold_data.shape[:3])*100:.2f}%\")\n",
    "print('bold_data masked shape:', masked_bold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6edd32c",
   "metadata": {},
   "source": [
    "Load Beta values, Mask it, Find threshold to determine and delete outlier voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_dict = np.load(f'TYPED_FITHRF_GLMDENOISE_RR_sub{sub}.npy', allow_pickle=True).item()\n",
    "beta_glm = glm_dict['betasmd']\n",
    "beta_run1, beta_run2 = beta_glm[:,0,0,:90], beta_glm[:,0,0,90:]\n",
    "\n",
    "if run == 1:\n",
    "    beta = beta_run1[keep_voxels]\n",
    "else:\n",
    "    beta = beta_run2[keep_voxels]\n",
    "print(\"Beta Range:[\", np.nanmin(beta), np.nanmax(beta), \"], Mean: \", np.nanmean(beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9845485",
   "metadata": {},
   "source": [
    "check how many trials for each voxel have outlier beta (shows my previous method is incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_thr, upper_thr = np.nanpercentile(beta, [1, 99])\n",
    "# print(f'low_thr: {lower_thr:.2f}, high_thr: {upper_thr:.2f}') #low_thr: -4.64, high_thr: 4.60\n",
    "# beta_extreme_mask = np.logical_or(beta < lower_thr, beta > upper_thr)\n",
    "# voxels_with_extreme_beta = np.any(beta_extreme_mask, axis=1)\n",
    "\n",
    "# print(f\"percentage of voxels with extreme beta values: {np.sum(voxels_with_extreme_beta)/beta.shape[0]*100:.2f}%\")\n",
    "\n",
    "# mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "# mask &= ~white_mask_data\n",
    "# nonzero_mask = np.where(mask)\n",
    "\n",
    "# clean_beta = beta[~voxels_with_extreme_beta]\n",
    "# print('clean_beta shape:', clean_beta.shape)\n",
    "\n",
    "# # This figure is related to my previous calculation (remove voxels even if they have one trial)\n",
    "# tmp = np.sum(beta_extreme_mask[voxels_with_extreme_beta, :], axis=1)\n",
    "# plt.hist(tmp)\n",
    "# plt.xlabel('Num_trials')\n",
    "# plt.ylabel(\"voxel count\")\n",
    "# plt.title('Trial-level Outlier Counts in Voxels with Extreme Beta')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ece6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(np.mean(beta, axis=1))\n",
    "# axs[0].set_title('Mean')\n",
    "# axs[1].hist(np.var(beta, axis=1))\n",
    "# axs[1].set_title('Var')\n",
    "# plt.suptitle('Original Beta')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a892e2b",
   "metadata": {},
   "source": [
    "Normalize beta value, remove voxels with most of trials have bad beta value, interpolate rest of the beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outlier beta after normalization\n",
    "med = np.nanmedian(beta, keepdims=True)\n",
    "mad = np.nanmedian(np.abs(beta - med), keepdims=True)\n",
    "scale = 1.4826 * np.maximum(mad, 1e-9)    \n",
    "beta_norm = (beta - med) / scale      \n",
    "thr = np.nanpercentile(np.abs(beta_norm), 99.9)\n",
    "outlier_mask = np.abs(beta_norm) > thr      \n",
    "print(f\"{np.sum(np.any(outlier_mask, axis=1))/beta.shape[0]*100:.2f}% voxels with at least one outlier beta\")\n",
    "\n",
    "# detect how many trials are bad for selected voxels\n",
    "beta_clean = beta.copy()\n",
    "trials = np.arange(beta.shape[1])\n",
    "voxel_outlier_fraction = np.sum(outlier_mask, axis=1)/outlier_mask.shape[1]*100\n",
    "valid_voxels = voxel_outlier_fraction <= 50\n",
    "beta_clean[~valid_voxels] = np.nan \n",
    "\n",
    "# save the selected voxels indices for later\n",
    "keeped_voxels_mask = ~np.all(np.isnan(beta_clean), axis=1)\n",
    "keeped_voxels_indices = np.flatnonzero(keeped_voxels_mask)\n",
    "\n",
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(np.mean(beta_clean, axis=1))\n",
    "# axs[0].set_title('Mean')\n",
    "# axs[1].hist(np.var(beta_clean, axis=1))\n",
    "# axs[1].set_title('Var')\n",
    "# plt.suptitle('After removing voxels (with 50% or higher trials with high beta)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# interpolate beta value for voxels which have less than 50% of trials as bad\n",
    "orig_outlier = []\n",
    "intrp_outlier = []\n",
    "for v in np.flatnonzero(valid_voxels):\n",
    "    mask = outlier_mask[v]\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    good = ~mask\n",
    "    orig_outlier.append(beta[v, mask])\n",
    "    beta_clean[v, mask] = np.interp(trials[mask], trials[good], beta[v, good])\n",
    "    intrp_outlier.append(beta_clean[v, mask])\n",
    "\n",
    "# remove voxels that have more than 50% of trials bad beta value\n",
    "beta_clean1 = beta_clean[~np.all(np.isnan(beta_clean), axis=1)]\n",
    "print(f\"{(beta_clean.shape[0]-beta_clean1.shape[0])/beta_clean.shape[0]*100:.3f}% voxels have more than 50% trials with outlier\")\n",
    "clean_beta = beta_clean1\n",
    "clean_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(np.mean(clean_beta, axis=1))\n",
    "# axs[0].set_title('Mean')\n",
    "# axs[1].hist(np.var(clean_beta, axis=1))\n",
    "# axs[1].set_title('Var')\n",
    "# plt.suptitle('After Interpolation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import skew\n",
    "# from scipy.stats import kurtosis\n",
    "\n",
    "# skew_value = skew(clean_beta, axis=1)\n",
    "# kurt_value = kurtosis(clean_beta, axis=1)\n",
    "\n",
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(skew_value)\n",
    "# axs[0].set_title('Skewness')\n",
    "# axs[1].hist(kurt_value)\n",
    "# axs[1].set_title('kurtosis ')\n",
    "# plt.suptitle('After Interpolation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_bold = masked_bold[keeped_voxels_mask] \n",
    "num_trials = 90\n",
    "trial_len = 9\n",
    "clean_bold_reshape = np.zeros((clean_bold.shape[0], num_trials, trial_len))\n",
    "start = 0\n",
    "\n",
    "for i in range(num_trials):\n",
    "        end = start + trial_len\n",
    "        clean_bold_reshape[:, i, :] = clean_bold[:, start:end]\n",
    "        start += trial_len\n",
    "        if start == 270 or start == 560:   # your skips\n",
    "            start += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ec264",
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_var = np.mean(np.var(clean_bold_reshape, axis=1), axis=-1)\n",
    "beta_var = np.var(clean_beta, axis=-1)\n",
    "\n",
    "np.corrcoef(bold_var, beta_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39695ed5",
   "metadata": {},
   "source": [
    "Plot beta, clean_beta, interpolated beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a754d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hist_with_zoom_ranges(x, fig_title, zoom_ranges, main_bins=200, inset_bins=60, density=False):\n",
    "#     fig, ax = plt.subplots(figsize=(9,7))\n",
    "#     ax.hist(x, bins=main_bins, density=density, color='C0', alpha=0.85, edgecolor='none')\n",
    "#     ax.set_title(fig_title)\n",
    "#     ax.set_xlabel('beta')\n",
    "#     ax.set_ylabel('density' if density else 'count')\n",
    "\n",
    "#     inset_data = []\n",
    "#     for (lo, hi) in zoom_ranges:\n",
    "#         xin = x[(x >= lo) & (x <= hi)]\n",
    "#         counts, edges = np.histogram(xin, bins=inset_bins, range=(lo, hi), density=density)\n",
    "#         inset_data.append((lo, hi, xin, edges, counts))\n",
    "\n",
    "#     boxes = [(0.08, 0.08, 0.4, 0.34),\n",
    "#              (0.2, 0.3, 0.4, 0.4),\n",
    "#              (0.64, 0.08, 0.4, 0.34)]\n",
    "\n",
    "#     for (left, bottom, w, h), (lo, hi, xin, edges, counts) in zip(boxes, inset_data):\n",
    "#         axins = inset_axes(ax, width=f\"{w*100:.0f}%\", height=f\"{h*100:.0f}%\", bbox_to_anchor=(left, bottom, w, h), bbox_transform=ax.transAxes,\n",
    "#             loc='upper left', borderpad=0.8)\n",
    "\n",
    "#         if xin.size:\n",
    "#             axins.hist(xin, bins=edges, density=density, color='C0', alpha=0.95, edgecolor='none')\n",
    "#         else:\n",
    "#             axins.text(0.5, 0.5, 'no data', ha='center', va='center', fontsize=8, transform=axins.transAxes)\n",
    "\n",
    "#         axins.set_xlim(lo, hi)\n",
    "\n",
    "#         if counts.size:\n",
    "#             ymax = counts.max()\n",
    "#             axins.set_ylim(0, ymax * 1.1)\n",
    "#         else:\n",
    "#             axins.set_ylim(0, 1)\n",
    "\n",
    "#         axins.set_title(f\"[{lo}, {hi}]\", fontsize=9)\n",
    "#         axins.tick_params(labelsize=8)\n",
    "\n",
    "#         pp, p1, p2 = mark_inset(ax, axins, loc1=3, loc2=4, fc='none', ec='none')\n",
    "#         pp.set_visible(False)\n",
    "#         for con in (p1, p2):\n",
    "#             con.set_color('0.4')\n",
    "#             con.set_linewidth(1.2)\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     return fig, ax\n",
    "\n",
    "\n",
    "# x = np.concatenate(orig_outlier)\n",
    "# hist_with_zoom_ranges(x, 'Original Beta (for selected voxels)', ((-1500,-1000), (-100,100), (1000,2000)))\n",
    "# plt.show()\n",
    "\n",
    "# # x = np.concatenate(intrp_outlier)\n",
    "# # hist_with_zoom_ranges(x, 'Interpolated Beta (for selected voxels)')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248da8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before = np.concatenate(orig_outlier)     \n",
    "# after  = np.concatenate(intrp_outlier)  \n",
    "\n",
    "# n_bins = 200\n",
    "# xmin, xmax = np.percentile(before, [0.1, 99.9])\n",
    "# edges = np.linspace(xmin, xmax, n_bins + 1)\n",
    "# b_counts, _ = np.histogram(before, bins=edges)\n",
    "# a_counts, _ = np.histogram(after,   bins=edges)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(15, 4), gridspec_kw={\"wspace\": 0.3})\n",
    "# axs[0].hist(before, bins=edges, alpha=0.45, label='Before', color='C0')\n",
    "# axs[0].hist(after,   bins=edges, alpha=0.45, label='After',  color='C1')\n",
    "# axs[0].set_title('Beta bafore & after interpolation')\n",
    "# axs[0].set_ylabel('count')\n",
    "# axs[0].legend()\n",
    "\n",
    "# centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "# delta = a_counts - b_counts\n",
    "# axs[1].bar(centers, delta, width=np.diff(edges), align='center', color='C2', alpha=0.8)\n",
    "# axs[1].axhline(0, color='0.3', lw=1)\n",
    "# axs[1].set_title('Per-bin change (After − Before)')\n",
    "# axs[1].set_xlabel('beta')\n",
    "# axs[1].set_ylabel('Δ count')\n",
    "\n",
    "# zoom_ranges = [(-800, -250), (250, 1000)]\n",
    "# positions = [(0.1, 0.4, 0.5, 0.5),   \n",
    "#              (0.6, 0.4, 0.5, 0.5)]   \n",
    "\n",
    "# for (lo, hi), (lx, ly, lw, lh) in zip(zoom_ranges, positions):\n",
    "#     axins = inset_axes(axs[1],\n",
    "#                        width=f\"{lw*100:.0f}%\",\n",
    "#                        height=f\"{lh*100:.0f}%\",\n",
    "#                        bbox_to_anchor=(lx, ly, lw, lh),\n",
    "#                        bbox_transform=axs[1].transAxes,\n",
    "#                        loc='upper left',\n",
    "#                        borderpad=0.8)\n",
    "#     mask = (centers >= lo) & (centers <= hi)\n",
    "#     axins.bar(centers[mask], delta[mask], width=np.diff(edges)[mask], align='center', color='C2', alpha=0.8)\n",
    "#     axins.axhline(0, color='0.3', lw=1)\n",
    "#     axins.set_xlim(lo, hi)\n",
    "#     axins.set_title(f\"[{lo},{hi}]\", fontsize=8)\n",
    "#     axins.tick_params(labelsize=7)\n",
    "\n",
    "#     pp, p1, p2 = mark_inset(axs[1], axins, loc1=3, loc2=4, fc='none', ec='none')\n",
    "#     pp.set_visible(False)\n",
    "#     for con in (p1, p2):\n",
    "#         con.set_color('0.4')\n",
    "#         con.set_linewidth(1.2)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bfa28",
   "metadata": {},
   "source": [
    "Plot outlier voxel on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme_volume = np.zeros(bold_img.shape[:3], dtype=np.float32)\n",
    "# nonzero_mask_kept = tuple(axis[keep_voxels] for axis in nonzero_mask)\n",
    "\n",
    "# extreme_volume[nonzero_mask_kept] = (~valid_voxels).astype(np.float32)\n",
    "# extreme_img = nib.Nifti1Image(extreme_volume, bold_img.affine, bold_img.header)\n",
    "# extreme_img = resample_to_img(extreme_img, anat_img, interpolation='nearest')\n",
    "# view = plotting.view_img(extreme_img, bg_img=anat_img, cmap='autumn', symmetric_cmap=False, threshold=0.5, vmax=1, opacity=0.9, title='Voxels with Extreme Betas')\n",
    "# view\n",
    "# view.save_as_html(file_name=f'rejected_voxels_sub{sub}_ses{ses}_run{run}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a1c54",
   "metadata": {},
   "source": [
    "Apply t-test and FDR, detect & remove non-active voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample t-test against 0\n",
    "tvals, pvals = ttest_1samp(clean_beta, popmean=0, axis=1, nan_policy='omit')\n",
    "\n",
    "# FDR correction\n",
    "tested = np.isfinite(pvals)\n",
    "alpha=0.05\n",
    "rej, q, _, _ = multipletests(pvals[tested], alpha=alpha, method='fdr_bh')\n",
    "\n",
    "n_voxel = clean_beta.shape[0]\n",
    "qvals  = np.full(n_voxel, np.nan)\n",
    "reject = np.zeros(n_voxel, dtype=bool)\n",
    "reject[tested] = rej\n",
    "qvals[tested]  = q\n",
    "\n",
    "# reject non-active voxels\n",
    "clean_active_beta = clean_beta[reject]\n",
    "print(f\"{clean_active_beta.shape[0]/clean_beta.shape[0]*100:.2f}% of voxels are active at FDR q<{alpha}\")\n",
    "clean_active_beta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072b8d3",
   "metadata": {},
   "source": [
    "Create 3-D beta dataset to use it for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_active_beta_4d = np.full(bold_img.shape[:3]+(clean_beta.shape[1],), np.nan)\n",
    "# active_indices = keeped_voxels_indices[reject]\n",
    "# active_coords = tuple(axis[active_indices] for axis in nonzero_mask)\n",
    "\n",
    "kept_flat_indices = np.flatnonzero(keep_voxels)\n",
    "kept_coords = tuple(axis[kept_flat_indices] for axis in nonzero_mask)\n",
    "active_flat_indices = kept_flat_indices[keeped_voxels_indices[reject]]\n",
    "active_coords = tuple(axis[active_flat_indices] for axis in nonzero_mask)\n",
    "\n",
    "clean_active_beta_4d[active_coords + (slice(None), )] = clean_active_beta\n",
    "clean_active_beta_4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transfer back beta value on the volume\n",
    "# clean_mask = ~np.asarray(voxels_with_extreme_beta, dtype=bool)\n",
    "# clean_indices = np.nonzero(clean_mask)[0]\n",
    "# active_indices = clean_indices[np.asarray(reject, dtype=bool)]\n",
    "\n",
    "# spatial_shape = bold_img.shape[:3]\n",
    "# n_trials = clean_active_beta.shape[1]\n",
    "# beta_volume = np.full(spatial_shape + (n_trials,), np.nan, dtype=np.float32)\n",
    "\n",
    "# coords = tuple(axis[active_indices] for axis in nonzero_mask)\n",
    "# beta_volume[coords[0], coords[1], coords[2], :] = clean_active_beta.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec597c5",
   "metadata": {},
   "source": [
    "Map mean beta for active voxels back into anatomical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a783c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_active_beta_4d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean_mask = ~np.asarray(voxels_with_extreme_beta, dtype=bool)\n",
    "# clean_indices = np.flatnonzero(clean_mask)\n",
    "# active_mask = np.asarray(reject, dtype=bool)\n",
    "# active_indices = clean_indices[active_mask]\n",
    "\n",
    "\n",
    "# active_voxel_coords = tuple(idx[active_indices] for idx in nonzero_mask)\n",
    "\n",
    "# mean_active_beta = np.nanmean(clean_active_beta, axis=1).astype(np.float32)\n",
    "# mean_beta_volume = np.full(bold_img.shape[:3], np.nan, dtype=np.float32)\n",
    "# mean_beta_volume[active_voxel_coords] = mean_active_beta\n",
    "\n",
    "mean_beta_volume = np.nanmean(clean_active_beta_4d, axis=-1)\n",
    "\n",
    "mean_beta_img = nib.Nifti1Image(mean_beta_volume, bold_img.affine, bold_img.header)\n",
    "mean_beta_img = resample_to_img(mean_beta_img, anat_img, interpolation='linear')\n",
    "\n",
    "# finite_vals = np.isfinite(mean_active_beta)\n",
    "# if np.any(finite_vals):\n",
    "#     vmax = np.nanpercentile(mean_active_beta[finite_vals], 99)\n",
    "#     vmin = np.nanpercentile(mean_active_beta[finite_vals], 1)\n",
    "# else:\n",
    "#     vmax = vmin = 0.0\n",
    "\n",
    "active_beta_view = plotting.view_img(\n",
    "    mean_beta_img,\n",
    "    bg_img=anat_img,\n",
    "    cmap='seismic',\n",
    "    symmetric_cmap=False,\n",
    "    threshold=1e-6,\n",
    "    # vmax=vmax,\n",
    "    # vmin=vmin,\n",
    "    colorbar=True,\n",
    "    title='Mean beta for active voxels'\n",
    ")\n",
    "active_beta_view\n",
    "active_beta_view.save_as_html(file_name=f'active_beta_map_sub{sub}_ses{ses}_run{run}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78578f26",
   "metadata": {},
   "source": [
    "Apply Hampel Filter to have smooth beta value (remove voxels that have 0-2 neighbour, smooth beta for voxles with more than 2 neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel_filter_image(image, window_size, threshold_factor, return_stats=False):\n",
    "    if window_size % 2 == 0:\n",
    "        raise ValueError(\"window_size must be odd\")\n",
    "\n",
    "    filtered = image.astype(float).copy()\n",
    "    footprint = np.ones((window_size,) * 3, dtype=bool)\n",
    "\n",
    "    insufficient_counts = []\n",
    "    corrected_indices_parts = []\n",
    "\n",
    "    for t in range(image.shape[3]):\n",
    "        vol = image[..., t]\n",
    "        med = ndimage.generic_filter(vol, np.nanmedian, footprint=footprint, mode='constant', cval=np.nan)\n",
    "        mad = ndimage.generic_filter(np.abs(vol - med), np.nanmedian, footprint=footprint, mode='constant', cval=np.nan)\n",
    "        counts = ndimage.generic_filter(np.isfinite(vol).astype(np.float32), np.sum, footprint=footprint, mode='constant', cval=0)\n",
    "\n",
    "        scaled_mad = 1.4826 * mad\n",
    "        insufficient = counts < 3\n",
    "        insufficient_counts.append(int(np.count_nonzero(insufficient)))\n",
    "\n",
    "        filtered[..., t][insufficient] = np.nan\n",
    "\n",
    "        valid = np.isfinite(vol)\n",
    "        enough_data = (~insufficient) & valid\n",
    "        outliers = enough_data & (np.abs(vol - med) > threshold_factor * scaled_mad)\n",
    "\n",
    "        if np.any(outliers):\n",
    "            coords = np.argwhere(outliers)\n",
    "            t_column = np.full((coords.shape[0], 1), t, dtype=int)\n",
    "            corrected_indices_parts.append(np.hstack((coords, t_column)))\n",
    "\n",
    "        filtered[..., t][outliers] = med[outliers]\n",
    "\n",
    "    if return_stats:\n",
    "        insufficient_counts_arr = np.array(insufficient_counts, dtype=int)\n",
    "        if corrected_indices_parts:\n",
    "            corrected_indices = np.vstack(corrected_indices_parts)\n",
    "        else:\n",
    "            corrected_indices = np.empty((0, 4), dtype=int)\n",
    "\n",
    "        stats = {\n",
    "            'insufficient_counts': insufficient_counts_arr,\n",
    "            'insufficient_total': int(insufficient_counts_arr.sum()),\n",
    "            'corrected_indices': corrected_indices,\n",
    "            'corrected_total': int(corrected_indices.shape[0]),\n",
    "        }\n",
    "        return filtered, stats\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "beta_volume_filter, hampel_stats = hampel_filter_image(beta_volume, window_size=5, threshold_factor=3, return_stats=True)\n",
    "print('Insufficient neighbours per frame:', hampel_stats['insufficient_counts'], flush=True)\n",
    "print('Total voxels with <3 neighbours:', hampel_stats['insufficient_total'], flush=True)\n",
    "print('Total corrected voxels:', hampel_stats['corrected_total'], flush=True)\n",
    "if hampel_stats['corrected_total'] > 0:\n",
    "    preview = hampel_stats['corrected_indices'][:5]\n",
    "    print('Sample corrected voxel indices (x, y, z, t):', preview, flush=True)\n",
    "\n",
    "# save cleaned beta volume\n",
    "np.save(f'cleaned_beta_volume_sub{sub}_ses{ses}_run{run}.npy', beta_volume_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cleaned beta volume to a 2D array for optimization\n",
    "beta_volume_filter = np.load('beta_valume_clean_2d.npy')\n",
    "beta_volume_filter = beta_volume_filter.astype(np.float16)\n",
    "spatial_shape = beta_volume_filter.shape[:-1]\n",
    "voxels_with_any_nan = np.zeros(spatial_shape, dtype=bool)\n",
    "voxels_with_all_nan = np.ones(spatial_shape, dtype=bool)\n",
    "\n",
    "# Sweep the time dimension once\n",
    "for t in range(beta_volume_filter.shape[-1]):\n",
    "    frame_nan = np.isnan(beta_volume_filter[..., t])\n",
    "    voxels_with_any_nan |= frame_nan\n",
    "    voxels_with_all_nan &= frame_nan\n",
    "\n",
    "print(np.sum(voxels_with_any_nan), np.sum(voxels_with_all_nan), flush=True)\n",
    "\n",
    "n_trial = beta_volume_filter.shape[-1]\n",
    "beta_volume_filter_2d = beta_volume_filter.reshape(-1, n_trial)\n",
    "print(beta_volume_filter_2d.shape, flush=True)\n",
    "mask_2d = voxels_with_all_nan.reshape(-1)\n",
    "beta_valume_clean_2d = beta_volume_filter_2d[~mask_2d]\n",
    "print(beta_valume_clean_2d.shape, flush=True)\n",
    "np.save(f'beta_valume_clean_2d.npy', beta_valume_clean_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del anat_img, back_mask, csf_mask, white_mask, mask, nonzero_mask, masked_bold\n",
    "del beta_run1, beta_run2, beta, clean_beta, voxels_with_all_nan, voxels_with_any_nan\n",
    "del beta_volume_filter_2d, beta_valume_clean_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25ee58",
   "metadata": {},
   "source": [
    "Plot finall beta value on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# choose what to visualize; here we use the across-trial mean\n",
    "beta_to_plot = np.nanmean(beta_valume_clean_2d.astype(np.float32), axis=1)\n",
    "\n",
    "# lift the 1-D beta array back into the 3-D volume\n",
    "beta_volume_overlay = np.full(mask_2d.shape, np.nan, dtype=np.float32)\n",
    "beta_volume_overlay[~mask_2d] = beta_to_plot\n",
    "beta_volume_overlay = beta_volume_overlay.reshape(bold_img.shape[:3])\n",
    "\n",
    "beta_img = nib.Nifti1Image(beta_volume_overlay, bold_img.affine, header=bold_img.header)\n",
    "\n",
    "# match anatomical space before plotting\n",
    "beta_img_on_anat = resample_to_img(beta_img, anat_img, interpolation='nearest')\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    beta_img_on_anat,\n",
    "    bg_img=anat_img,\n",
    "    cmap='cold_hot',\n",
    "    threshold=None,        # set to e.g. 0.5 if you want to mask small values\n",
    "    symmetric_cbar=True,\n",
    "    colorbar=True,\n",
    "    title='Mean beta overlay'\n",
    ")\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15460be",
   "metadata": {},
   "source": [
    "Load the clean beta, which is ready for optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_valume_clean_2d = np.load(f'beta_valume_clean_2d.npy')\n",
    "beta_valume_clean_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652db5f",
   "metadata": {},
   "source": [
    "Create Matrices for Optim problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrices(\n",
    "    beta_valume_clean_2d,\n",
    "    bold_data,\n",
    "    mask_2d,\n",
    "    trial_indices=None,\n",
    "    trial_len=9,\n",
    "    num_components=600,\n",
    "    pca_components=None,\n",
    "    pca_mean=None):\n",
    "    print(\"begin\", flush=True)\n",
    "    print(type(mask_2d))\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "    trial_idx = np.arange(num_trials) if trial_indices is None else np.unique(np.asarray(trial_indices, int).ravel())\n",
    "\n",
    "    # ----- reshape BOLD into trials -----\n",
    "    bold_data_reshape = bold_data.reshape(-1, bold_data.shape[-1])\n",
    "    print(bold_data.reshape(-1, bold_data.shape[-1]).shape[0], mask_2d.dtype, mask_2d.size)\n",
    "    bold_data_selected = bold_data_reshape[~mask_2d]         # keep voxels of interest\n",
    "    bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len), dtype=np.float32)\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        end = start + trial_len\n",
    "        if end > bold_data_selected.shape[1]:\n",
    "            raise ValueError(\"BOLD data does not contain enough timepoints for all trials\")\n",
    "        bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:end]\n",
    "        start += trial_len\n",
    "        if start == 270 or start == 560:   # your skips\n",
    "            start += 20\n",
    "    X = bold_data_selected_reshape[:, trial_idx, :]          # [Nvox, Ntrials, T]\n",
    "    print(\"BOLD reshaped before PCA\", X.shape, flush=True)\n",
    "\n",
    "    # ----- apply PCA -----\n",
    "    print(\"PCA...\", flush=True)\n",
    "    X_reshap = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "\n",
    "    if pca_components is None or pca_mean is None:\n",
    "        pca = PCA()\n",
    "        X_pca_full = pca.fit_transform(X_reshap.T).astype(np.float32)\n",
    "        components = pca.components_.astype(np.float32)\n",
    "        mean = pca.mean_.astype(np.float32)\n",
    "        n_components = min(num_components, components.shape[0])\n",
    "        components = components[:n_components]\n",
    "        X_pca = X_pca_full[:, :n_components]\n",
    "    else:\n",
    "        components = pca_components.astype(np.float32)\n",
    "        mean = pca_mean.astype(np.float32)\n",
    "        n_components = components.shape[0]\n",
    "        X_centered = X_reshap.T - mean\n",
    "        X_pca = (X_centered @ components.T).astype(np.float32)\n",
    "\n",
    "    beta_reduced = (beta_valume_clean_2d.T - mean) @ components.T\n",
    "    beta_reduced = beta_reduced.T\n",
    "\n",
    "\n",
    "    # ----- L_task (same idea as yours) -----\n",
    "    print(\"L_task...\", flush=True)\n",
    "    beta_selected = beta_reduced[:, trial_idx]\n",
    "    counts = np.count_nonzero(np.isfinite(beta_selected), axis=-1)\n",
    "    sums = np.nansum(beta_selected, axis=-1, dtype=np.float64)\n",
    "    mean_beta = np.zeros(beta_selected.shape[0], dtype=np.float32)\n",
    "    m = counts > 0\n",
    "    mean_beta[m] = (sums[m] / counts[m]).astype(np.float32)\n",
    "    L_task = np.zeros_like(mean_beta, dtype=np.float32)\n",
    "    v = np.abs(mean_beta) > 0\n",
    "    L_task[v] = (1.0 / np.abs(mean_beta[v])).astype(np.float32)\n",
    "\n",
    "    # ----- L_var: variance of trial differences, as sparse diagonal -----\n",
    "    print(\"L_var...\", flush=True)\n",
    "    X_pca = X_pca[:, :n_components].T\n",
    "    num_trials = len(trial_idx)\n",
    "    X = X_pca.reshape(X_pca.shape[0], num_trials, trial_len)\n",
    "    L_var = np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)\n",
    "    for i in range(num_trials-1):\n",
    "        x1 = X[:, i, :]\n",
    "        x2 = X[:, i+1, :]\n",
    "        L_var += (x1-x2) @ (x1-x2).T\n",
    "    L_var /= (num_trials - 1)\n",
    "\n",
    "    selected_BOLD_flat = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "    return L_task.astype(np.float32), L_var, selected_BOLD_flat, components, mean\n",
    "\n",
    "# %%\n",
    "def objective_func(w, L_task, L_var, alpha_var):\n",
    "    print(\"Calculating objective...\", flush=True)\n",
    "    quad = (w.T @ np.diag(L_task) @ w + alpha_var * (w.T @ L_var @ w))\n",
    "    return quad\n",
    "\n",
    "# %%\n",
    "def optimize_voxel_weights(L_task, L_var, alpha_var):\n",
    "    print(\"Optimizing voxel weights...\", flush=True)\n",
    "    L_total = np.diag(L_task) + alpha_var * L_var\n",
    "    n = L_total.shape[0]\n",
    "    L_total = np.nan_to_num(L_total)\n",
    "    L_total = 0.5*(L_total + L_total.T) + 1e-6*np.eye(n)\n",
    "    eigvals, eigvecs = np.linalg.eigh(L_total)\n",
    "    eigvals[eigvals < 0] = 0.0  # clip the numerical negatives\n",
    "    L_total_psd = (eigvecs @ np.diag(eigvals) @ eigvecs.T).astype(np.float64)\n",
    "\n",
    "    w = cp.Variable(n, nonneg=True)\n",
    "    constraints = [cp.sum(w) == 1]\n",
    "\n",
    "    objective = cp.Minimize(cp.quad_form(w, cp.psd_wrap(L_total_psd)))\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.OSQP, verbose=True)\n",
    "    return w.value\n",
    "\n",
    "\n",
    "# %%\n",
    "def calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    best_score = np.inf\n",
    "    best_alpha_var = None\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "\n",
    "    for a_var in param_grid[\"alpha_var\"]:\n",
    "        fold_scores = []\n",
    "        print(f\"a_var: {a_var}\", flush=True)\n",
    "        count = 1\n",
    "\n",
    "        for train_idx, val_idx in kf.split(np.arange(num_trials)):\n",
    "            print(f\"k-fold num: {count}\", flush=True)\n",
    "            print(type(mask_2d), flush=True)\n",
    "            L_task_train, L_var_train, _, pca_components, pca_mean = calculate_matrices(\n",
    "                beta_valume_clean_2d,\n",
    "                bold_data,\n",
    "                mask_2d,\n",
    "                train_idx,\n",
    "                trial_len,\n",
    "            )\n",
    "            w = optimize_voxel_weights(L_task_train, L_var_train, alpha_var=a_var)\n",
    "\n",
    "            L_task_val, L_var_val, _, _, _ = calculate_matrices(\n",
    "                beta_valume_clean_2d,\n",
    "                bold_data,\n",
    "                mask_2d,\n",
    "                val_idx,\n",
    "                trial_len,\n",
    "                pca_components=pca_components,\n",
    "                pca_mean=pca_mean,\n",
    "            )\n",
    "\n",
    "            fold_scores.append(objective_func(w, L_task_val, L_var_val, a_var))\n",
    "            print(f\"fold_scores: {fold_scores}\", flush=True)\n",
    "            count += 1\n",
    "\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        print(mean_score)\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_alpha_var = a_var\n",
    "\n",
    "    print(\"Best alpha_var:\", best_alpha_var, \"with CV loss:\", best_score, flush=True)\n",
    "    return best_alpha_var, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f390527",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha_var\":   [0.1, 0.5, 0.9, 1.0, 2]}\n",
    "\n",
    "trial_len = 9\n",
    "best_alpha_var, best_score = calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len)\n",
    "L_task, L_var, selected_BOLD_flat, pca_components, pca_mean = calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, None, trial_len)\n",
    "print(f\"best alpha_var: {best_alpha_var}, best_score: {best_score}\", flush=True)\n",
    "weights = optimize_voxel_weights(L_task, L_var, alpha_var=best_alpha_var)\n",
    "voxel_space_weights = pca_components.T @ weights\n",
    "y = selected_BOLD_flat.T @ weights\n",
    "\n",
    "np.save('weights.npy', weights)\n",
    "np.save('voxel_space_weights.npy', voxel_space_weights)\n",
    "np.save('pca_components.npy', pca_components)\n",
    "np.save('pca_mean.npy', pca_mean)\n",
    "np.save('y.npy', y)\n",
    "print(\"Finished!\", flush=True)\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee10337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9745b0aa",
   "metadata": {},
   "source": [
    "Analysis the Optim Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_task = np.load('L_task.npy') # (600,)\n",
    "L_var = np.load('L_var.npy') # (600,600)\n",
    "voxel_space_weights = np.load('voxel_space_weights.npy') #(296838,)\n",
    "weights = np.load('weights.npy') # (600,)\n",
    "y = np.load('y.npy') #(810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(voxel_space_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for arr, lab in [(weights,'weights'), (L_task,'L_task')]:\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(arr, ax=ax, label=lab, fill=True, alpha=0.2)\n",
    "    ax.legend(); ax.set_title('Distribution comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af984cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "lower = np.percentile(L_var, 1)\n",
    "upper = np.percentile(L_var, 99)\n",
    "tmp = np.clip(L_var, lower, upper)\n",
    "im = ax.imshow(tmp, cmap='jet')\n",
    "fig.colorbar(im, ax=ax).set_label('L_var values')\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Heatmap of L_var Matrix')\n",
    "ax.set_xlabel('Component Index')\n",
    "ax.set_ylabel('Component Index')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f36021",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.sum(L_var, axis=0)\n",
    "plt.figure()\n",
    "plt.plot(tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[tmp>1e6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(L_var.ravel(), bins=100, alpha=0.7)\n",
    "plt.xlabel('voxel_space_weights'); plt.ylabel('count'); plt.title('Histogram')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f476e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(voxel_space_weights, bins=100, alpha=0.7)\n",
    "plt.xlabel('voxel_space_weights'); plt.ylabel('count'); plt.title('Histogram')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(y)\n",
    "plt.xlabel('index'); plt.ylabel('y'); plt.title('Target values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff26c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff4104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
