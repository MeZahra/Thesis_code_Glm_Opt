{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from nilearn import plotting\n",
    "from nilearn.image import resample_to_img\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse import csgraph\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import scipy.io as sio\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_mat_func(path):\n",
    "#     with h5py.File(path, \"r\") as f:\n",
    "#         def _read(obj):\n",
    "#             if isinstance(obj, h5py.Dataset):\n",
    "#                 # print(1)\n",
    "#                 data = obj[()]\n",
    "#                 if isinstance(data, (bytes, np.bytes_)):\n",
    "#                     return data.decode(\"utf-8\", errors=\"ignore\")\n",
    "#                 return np.array(data)\n",
    "#             # elif isinstance(obj, h5py.Group):\n",
    "#             #     print(2)\n",
    "#             #     return {k: _read(obj[k]) for k in obj.keys()}\n",
    "#             # else:\n",
    "#             #     print(3)\n",
    "#             #     return obj\n",
    "#         return {k: _read(f[k]) for k in f.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ses = 1\n",
    "# sub = '04'\n",
    "# run = 1\n",
    "# mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_1.nii.gz'\n",
    "# white_mask = nib.load(mask_path)\n",
    "# np.unique(white_mask.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(white_mask.get_fdata().ravel(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white_mask_data = white_mask.get_fdata() > 0.9\n",
    "\n",
    "# mask_volume = np.zeros(bold_data.shape[:3], dtype=np.uint8)\n",
    "# mask_volume[white_mask_data] = 1\n",
    "\n",
    "# # make sure it lines up with the anatomy\n",
    "# mask_img = nib.Nifti1Image(mask_volume, bold_img.affine, bold_img.header)\n",
    "# mask_img = resample_to_img(mask_img, anat_img, interpolation=\"nearest\")\n",
    "\n",
    "# # interactive overlay\n",
    "# view = plotting.view_img(\n",
    "#     mask_img,\n",
    "#     bg_img=anat_img,\n",
    "#     cmap=\"autumn\",\n",
    "#     opacity=0.7,\n",
    "#     threshold=0,\n",
    "#     colorbar=False\n",
    "# )\n",
    "# view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = 1\n",
    "sub = '04'\n",
    "run = 1\n",
    "\n",
    "base_path = '/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives'\n",
    "anat_img = nib.load(f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain.nii.gz')\n",
    "\n",
    "data_name = f'sub-pd0{sub}_ses-{ses}_run-{run}_task-mv_bold_corrected_smoothed_reg.nii.gz'\n",
    "BOLD_path_org = join(base_path, f'sub-pd0{sub}', f'ses-{ses}', 'func', data_name)\n",
    "bold_img = nib.load(BOLD_path_org)\n",
    "bold_data = bold_img.get_fdata()\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_mask.nii.gz'\n",
    "back_mask = nib.load(mask_path)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_0.nii.gz'\n",
    "csf_mask = nib.load(mask_path)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_1.nii.gz'\n",
    "white_mask = nib.load(mask_path)\n",
    "\n",
    "# print(anat_img.shape)\n",
    "# print(bold_data.shape)\n",
    "# print(back_mask.shape)\n",
    "# print(csf_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ses = 1\n",
    "# sub = '04'\n",
    "# run = 1\n",
    "\n",
    "# base_path = '/home/zkavian/thesis_code_git/Optim_fMRI/Optim_fMRI_new/'\n",
    "# anat_img = nib.load(f'sub-pd0{sub}_ses-{ses}_T1w_brain.nii.gz')\n",
    "# print(1)\n",
    "\n",
    "# # data_name = f'fmri_sub{sub}_ses{ses}_run{run}.mat'\n",
    "# # BOLD_path_org = join(base_path, data_name)\n",
    "# # # bold_img = sio.loadmat(BOLD_path_org)\n",
    "# # bold_mat = load_mat_func(BOLD_path_org)\n",
    "# # bold_data = bold_img.get_fdata()\n",
    "\n",
    "# base_path = '/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives'\n",
    "# data_name = f'sub-pd0{sub}_ses-{ses}_run-{run}_task-mv_bold_corrected_smoothed_reg.nii.gz'\n",
    "# BOLD_path_org = join(base_path, f'sub-pd0{sub}', f'ses-{ses}', 'func', data_name)\n",
    "# bold_img = nib.load(BOLD_path_org)\n",
    "# bold_data = bold_img.get_fdata()\n",
    "# print(2)\n",
    "\n",
    "# mask_path = f'sub-pd0{sub}_ses-{ses}_T1w_brain_mask.nii.gz'\n",
    "# back_mask = nib.load(mask_path)\n",
    "# print(3)\n",
    "\n",
    "# mask_path = f'sub-pd0{sub}_ses-{ses}_T1w_brain_pve_0.nii.gz'\n",
    "# csf_mask = nib.load(mask_path)\n",
    "# print(4)\n",
    "\n",
    "# # print(anat_img.shape)\n",
    "# # print(bold_data.shape)\n",
    "# # print(back_mask.shape)\n",
    "# # print(csf_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected voxels after masking: 7.91%\n",
      "bold_data masked shape: (619385, 850)\n"
     ]
    }
   ],
   "source": [
    "back_mask_data = back_mask.get_fdata() > 0\n",
    "csf_mask_data = csf_mask.get_fdata() > 0\n",
    "white_mask_data = white_mask.get_fdata() > 0.5\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "mask &= ~white_mask_data\n",
    "nonzero_mask = np.where(mask)\n",
    "masked_bold = bold_data[nonzero_mask]\n",
    "\n",
    "print(f\"number of selected voxels after masking: {masked_bold.shape[0]/math.prod(bold_data.shape[:3])*100:.2f}%\")\n",
    "print('bold_data masked shape:', masked_bold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_thr: -4.41, high_thr: 4.42\n",
      "percentage of voxels with extreme beta values: 7.53%\n"
     ]
    }
   ],
   "source": [
    "glm_dict = np.load(f'TYPED_FITHRF_GLMDENOISE_RR.npy', allow_pickle=True).item()\n",
    "beta_glm = glm_dict['betasmd']\n",
    "beta_run1, beta_run2 = beta_glm[:,0,0,:90], beta_glm[:,0,0,90:]\n",
    "R2_run1, R2_run2 = glm_dict['R2run'][:,:,:,0], glm_dict['R2run'][:,:,:,1]\n",
    "\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "nonzero_mask = np.where(mask)\n",
    "white_mask_flat = white_mask_data[nonzero_mask]\n",
    "beta = beta_run1[~white_mask_flat]\n",
    "R2 = R2_run1[~white_mask_flat]\n",
    "\n",
    "lower_thr, upper_thr = np.nanpercentile(beta, [1, 99])\n",
    "print(f'low_thr: {lower_thr:.2f}, high_thr: {upper_thr:.2f}') #low_thr: -4.64, high_thr: 4.60\n",
    "beta_extreme_mask = np.logical_or(beta < lower_thr, beta > upper_thr)\n",
    "voxels_with_extreme_beta = np.any(beta_extreme_mask, axis=1)\n",
    "\n",
    "print(f\"percentage of voxels with extreme beta values: {np.sum(voxels_with_extreme_beta)/beta.shape[0]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "mask &= ~white_mask_data\n",
    "nonzero_mask = np.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extreme_beta_volume = np.full(bold_data.shape[:3], np.nan)\n",
    "# # extreme_indices = np.nonzero(voxels_with_extreme_beta)[0]\n",
    "# # extreme_beta_value = np.nanmean(beta[extreme_indices], axis=1)\n",
    "\n",
    "# # extreme_voxel_coords = tuple(idx[extreme_indices] for idx in nonzero_mask)\n",
    "# # extreme_beta_volume[extreme_voxel_coords] = extreme_beta_value\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(extreme_beta_volume.ravel(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23524394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # visualize beta values for voxels flagged as extreme\n",
    "# # extreme_beta_volume = np.full(bold_data.shape[:3], np.nan, dtype=np.float32)\n",
    "\n",
    "# # extreme_indices = np.nonzero(voxels_with_extreme_beta)[0]\n",
    "\n",
    "# # extreme_beta_values = np.nanmean(beta[voxels_with_extreme_beta], axis=-1)\n",
    "# # coords = tuple(axis[extreme_indices] for axis in nonzero_mask)\n",
    "# # extreme_beta_volume[coords] = extreme_beta_values.astype(np.float32)\n",
    "\n",
    "# extreme_beta_img = nib.Nifti1Image(extreme_beta_volume, bold_img.affine, bold_img.header)\n",
    "# nib.save(extreme_beta_img, f'extreme_beta_sub{sub}_ses{ses}_run{run}.nii.gz')\n",
    "# extreme_beta_img_rs = resample_to_img(extreme_beta_img, anat_img, interpolation='nearest')\n",
    "# extreme_beta_view = plotting.view_img(\n",
    "#     extreme_beta_img_rs,\n",
    "#     bg_img=anat_img,\n",
    "#     cmap='cold_hot',\n",
    "#     symmetric_cmap=True,\n",
    "#     colorbar=True,\n",
    "#     title='Extreme beta voxels on anatomy'\n",
    "# )\n",
    "# extreme_beta_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_volume = np.full(bold_data.shape[:3], np.nan, dtype=np.float32)\n",
    "# beta_volume[nonzero_mask] = np.nanmean(beta, axis=-1)\n",
    "\n",
    "# # img = nib.Nifti1Image(beta_volume, bold_img.affine, bold_img.header)\n",
    "# # nib.save(img, f'sub{sub}_ses{ses}_run{run}_meanBeta.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plot_func import cfs_brain_mask_plot, mean_beta_outlier_voxels, csf_mask_with_outlier, check_beta_range_and_outliers, check_avg_beta_range\n",
    "\n",
    "# overlay_view = cfs_brain_mask_plot(nonzero_mask, mask, bold_img, anat_img)\n",
    "# overlay_view\n",
    "# mean_beta_outlier_voxels(beta, bold_data, bold_img, anat_img, nonzero_mask, sub, ses, run)\n",
    "# overlay_img = csf_mask_with_outlier(csf_mask_data, voxels_with_extreme_beta, bold_data, bold_img, anat_img, nonzero_mask, sub, ses, run)\n",
    "# nib.save(overlay_img, f'sub{sub}_ses{ses}_run{run}_outlier_csf_mask.nii.gz')\n",
    "# check_beta_range_and_outliers(beta, bold_data, bold_img, anat_img, nonzero_mask)\n",
    "# check_avg_beta_range(beta, bold_data, bold_img, anat_img, nonzero_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after removing voxels with extreme beta values\n",
    "clean_beta = beta[~voxels_with_extreme_beta]\n",
    "clean_R2 = R2[~voxels_with_extreme_beta]\n",
    "print('clean_beta shape:', clean_beta.shape)\n",
    "\n",
    "# one sample t-test against 0\n",
    "tvals, pvals = ttest_1samp(clean_beta, popmean=0, axis=1, nan_policy='omit')\n",
    "\n",
    "# FDR correction\n",
    "tested = np.isfinite(pvals)\n",
    "alpha=0.05\n",
    "rej, q, _, _ = multipletests(pvals[tested], alpha=alpha, method='fdr_bh')\n",
    "\n",
    "n_voxel = clean_beta.shape[0]\n",
    "qvals  = np.full(n_voxel, np.nan)\n",
    "reject = np.zeros(n_voxel, dtype=bool)\n",
    "reject[tested] = rej\n",
    "qvals[tested]  = q\n",
    "\n",
    "# reject non-active voxels\n",
    "clean_active_beta = clean_beta[reject]\n",
    "clean_active_R2 = clean_R2[reject]\n",
    "print(f\"{clean_active_beta.shape[0]/clean_beta.shape[0]*100:.2f}% of voxels are active at FDR q<{alpha}\")\n",
    "\n",
    "# # plot hist and beta values of ative voxels\n",
    "# from plot_func import active_voxel_plot\n",
    "# active_voxel_plot(clean_active_beta, voxels_with_extreme_beta, reject, bold_img, anat_img, nonzero_mask, sub, ses, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clean_active_beta.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer back beta value on the volume\n",
    "clean_mask = ~np.asarray(voxels_with_extreme_beta, dtype=bool)\n",
    "clean_indices = np.nonzero(clean_mask)[0]\n",
    "active_indices = clean_indices[np.asarray(reject, dtype=bool)]\n",
    "\n",
    "spatial_shape = bold_img.shape[:3]\n",
    "n_trials = clean_active_beta.shape[1]\n",
    "beta_volume = np.full(spatial_shape + (n_trials,), np.nan, dtype=np.float32)\n",
    "\n",
    "coords = tuple(axis[active_indices] for axis in nonzero_mask)\n",
    "beta_volume[coords[0], coords[1], coords[2], :] = clean_active_beta.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel_filter_image(image, window_size, threshold_factor):\n",
    "    if window_size % 2 == 0:\n",
    "        raise ValueError(\"window_size must be odd\")\n",
    "        \n",
    "    filtered = image.astype(float).copy()\n",
    "    footprint = np.ones((window_size,)*3, dtype=bool)\n",
    "\n",
    "    print(image.shape[3])\n",
    "    for t in range(image.shape[3]):\n",
    "        print(t)\n",
    "        vol = image[..., t]\n",
    "        med = ndimage.generic_filter(vol, np.nanmedian, footprint=footprint, mode='constant', cval=np.nan)\n",
    "        mad = ndimage.generic_filter(np.abs(vol - med), np.nanmedian, footprint=footprint, mode='constant', cval=np.nan)\n",
    "\n",
    "        scaled_mad = 1.4826 * mad  # Gaussian-consistent scaling\n",
    "        valid = ~np.isnan(vol)\n",
    "        outliers = valid & (np.abs(vol - med) > threshold_factor * scaled_mad)\n",
    "        filtered[..., t][outliers] = np.nan\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_volume_filter = hampel_filter_image(beta_volume, window_size=5, threshold_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(beta_volume_filter.shape)\n",
    "\n",
    "# stat_img = nib.Nifti1Image(np.nanmean(beta_volume_filter, axis=-1), bold_img.affine, bold_img.header)\n",
    "# stat_img = resample_to_img(stat_img, anat_img, interpolation='linear')\n",
    "\n",
    "# view = plotting.view_img(stat_img, bg_img=anat_img, cmap='jet', colorbar=True, title='Mean beta for active voxels')\n",
    "# view.save_as_html(f'mean_beta_sub{sub}_ses{ses}_run{run}_after_hampel.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(beta_volume_filter.ravel(), bins=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"beta_volume_filter.npy\",beta_volume_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_volume_filter = np.load(\"beta_volume_filter.npy\")\n",
    "bold_data = bold_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30, 850)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "beta_volume_filter = beta_volume_filter[45:75, 80:110, 40:70, :]\n",
    "bold_data = bold_data[45:75, 80:110, 40:70, :]\n",
    "bold_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20963 18437\n",
      "(27000, 90)\n",
      "(8563, 90)\n"
     ]
    }
   ],
   "source": [
    "spatial_shape = beta_volume_filter.shape[:-1]\n",
    "voxels_with_any_nan = np.zeros(spatial_shape, dtype=bool)\n",
    "voxels_with_all_nan = np.ones(spatial_shape, dtype=bool)\n",
    "\n",
    "# Sweep the time dimension once\n",
    "for t in range(beta_volume_filter.shape[-1]):\n",
    "    frame_nan = np.isnan(beta_volume_filter[..., t])\n",
    "    voxels_with_any_nan |= frame_nan\n",
    "    voxels_with_all_nan &= frame_nan\n",
    "\n",
    "print(np.sum(voxels_with_any_nan), np.sum(voxels_with_all_nan))\n",
    "\n",
    "n_trial = beta_volume_filter.shape[-1]\n",
    "beta_volume_filter_2d = beta_volume_filter.reshape(-1, n_trial)\n",
    "print(beta_volume_filter_2d.shape)\n",
    "mask_2d = voxels_with_all_nan.reshape(-1)\n",
    "beta_valume_clean_2d = beta_volume_filter_2d[~mask_2d]\n",
    "print(beta_valume_clean_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_volume_filter_reshape = beta_valume_clean_2d.reshape(-1, beta_valume_clean_2d.shape[-1])\n",
    "# mean_beta_filtered = np.nanmean(beta_volume_filter_reshape, axis=-1)\n",
    "# print(f\"Beta range: {np.nanmin(mean_beta_filtered):.2f} to {np.nanmax(mean_beta_filtered):.2f}\")\n",
    "\n",
    "# L_task = np.divide(1., np.abs(mean_beta_filtered), where=mean_beta_filtered!=0)\n",
    "# np.save(\"L_task.npy\",L_task)\n",
    "# print(f\"L_task range: {np.nanmin(L_task):.2f} to {np.nanmax(L_task):.2f}\")\n",
    "\n",
    "# # # plt.figure()\n",
    "# # # plt.hist(L_task)\n",
    "# # # plt.show()\n",
    "\n",
    "# # # np.where((mean_beta_filtered <0.0001) & (mean_beta_filtered> 0))\n",
    "# # # np.where(abs(mean_beta_filtered) >0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_task.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite_counts = np.sum(np.isfinite(beta_volume), axis=-1)\n",
    "# tmp = finite_counts[finite_counts>80]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(finite_counts.ravel(), bins=30)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(tmp)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finite_counts = np.sum(np.isfinite(beta_volume), axis=-1)\n",
    "# # min_finite_betas = 0\n",
    "# # valid_mask = finite_counts > min_finite_betas\n",
    "# # coords = np.argwhere(valid_mask)\n",
    "# bold_data_reshape = np.reshape(bold_data, (-1, bold_data.shape[-1]))\n",
    "# bold_data_selected = bold_data_reshape[~mask_2d]\n",
    "\n",
    "# print(0)\n",
    "# # bold_data_selected = np.reshape(bold_data_selected, (-1, bold_data.shape[-1]))\n",
    "# num_trials= 90\n",
    "# trial_len = 9\n",
    "# bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len))\n",
    "\n",
    "# print(1)\n",
    "# start = 0\n",
    "# for i in range(num_trials):\n",
    "#     bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:start+trial_len]\n",
    "#     start += trial_len\n",
    "#     if start == 270 or start == 560:\n",
    "#         start += 20\n",
    "\n",
    "# print(2)\n",
    "# diff_mat = np.diff(bold_data_selected_reshape, axis=1)\n",
    "# diff_mat_flat = diff_mat.reshape(diff_mat.shape[0], -1)\n",
    "# L_var = np.cov(diff_mat_flat, bias=False, dtype=np.float32)\n",
    "# L_var = (L_var + L_var.T) / 2 + 1e-6 * np.eye(L_var.shape[0])\n",
    "# print(L_var.shape) # I need to reduce number of voxels at the end to 100,000 - 200,000 to make it computationally feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(L_var[:20,:20], cmap='hot', interpolation='nearest')\n",
    "# np.save(\"L_var.npy\",L_var)\n",
    "# print(\"L_var range: \",  np.nanmin(L_var), np.nanmax(L_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_slices = (slice(45, 75), slice(80, 110), slice(40, 70))\n",
    "# crop_offset = np.array([sl.start for sl in crop_slices])\n",
    "# mask_selected = (~mask_2d).reshape(bold_data.shape[:3])\n",
    "# selected_linear_idx = np.flatnonzero(mask_selected)\n",
    "\n",
    "# voxel_indices_local = np.column_stack(np.unravel_index(selected_linear_idx, bold_data.shape[:3]))\n",
    "# voxel_indices = voxel_indices_local + crop_offset\n",
    "# selected_world_coords = nib.affines.apply_affine(anat_img.affine, voxel_indices)\n",
    "# D = cdist(selected_world_coords, selected_world_coords)\n",
    "# nonzero = D[D > 0]\n",
    "# sigma = np.median(nonzero) if nonzero.size else 1.0\n",
    "# W = np.exp(-D**2 / (2.0 * sigma**2))\n",
    "# np.fill_diagonal(W, 0.0)\n",
    "# L_smooth = csgraph.laplacian(W, normed=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_smooth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(L_smooth.ravel(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(L_smooth, interpolation='nearest')\n",
    "# np.save(\"L_smooth.npy\",L_smooth)\n",
    "# print(\"L_smooth range: \",  np.nanmin(L_smooth), np.nanmax(L_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_valume_clean_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, trial_indices=None, trial_len=9):\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "    if trial_indices is None:\n",
    "        trial_idx = np.arange(num_trials)\n",
    "    else:\n",
    "        trial_idx = np.asarray(trial_indices, dtype=int).ravel()\n",
    "        trial_idx = np.unique(trial_idx)\n",
    "\n",
    "    beta_selected = beta_valume_clean_2d[:, trial_idx]\n",
    "    finite_mask = np.isfinite(beta_selected)\n",
    "    counts = np.count_nonzero(finite_mask, axis=-1)\n",
    "    sums = np.nansum(beta_selected, axis=-1, dtype=np.float64)\n",
    "    mean_beta_filtered = np.zeros(beta_selected.shape[0], dtype=beta_selected.dtype)\n",
    "    valid_counts = counts > 0\n",
    "    mean_beta_filtered[valid_counts] = np.asarray(sums[valid_counts] / counts[valid_counts], dtype=beta_selected.dtype)\n",
    "    L_task = np.zeros_like(mean_beta_filtered)\n",
    "    valid_mean = np.abs(mean_beta_filtered) > 0\n",
    "    L_task[valid_mean] = 1.0 / np.abs(mean_beta_filtered[valid_mean])\n",
    "\n",
    "###\n",
    "    bold_data_reshape = np.reshape(bold_data, (-1, bold_data.shape[-1]))\n",
    "    bold_data_selected = bold_data_reshape[~mask_2d]\n",
    "\n",
    "    bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len), dtype=bold_data_selected.dtype)\n",
    "    start = 0\n",
    "    for i in range(num_trials):\n",
    "        end = start + trial_len\n",
    "        if end > bold_data_selected.shape[1]:\n",
    "            raise ValueError(\"BOLD data does not contain enough timepoints for all trials\")\n",
    "        bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:end]\n",
    "        start += trial_len\n",
    "        if start == 270 or start == 560:\n",
    "            start += 20\n",
    "\n",
    "    selected_BOLD_data_subset = bold_data_selected_reshape[:, trial_idx, :]\n",
    "\n",
    "    diff_mat = np.diff(selected_BOLD_data_subset, axis=1)\n",
    "    diff_mat_flat = diff_mat.reshape(diff_mat.shape[0], -1)\n",
    "    finite_cols = np.all(np.isfinite(diff_mat_flat), axis=0)\n",
    "    if not np.all(finite_cols):\n",
    "        diff_mat_flat = diff_mat_flat[:, finite_cols]\n",
    "    if diff_mat_flat.shape[1] < 2:\n",
    "        raise ValueError(\"Not enough finite samples to compute covariance for L_var\")\n",
    "    L_var = np.cov(diff_mat_flat, bias=False, dtype=np.float32)\n",
    "    L_var = np.nan_to_num(L_var)\n",
    "    L_var = (L_var + L_var.T) / 2 + 1e-6 * np.eye(L_var.shape[0], dtype=np.float32)\n",
    "####\n",
    "\n",
    "    mask_selected = (~mask_2d).reshape(bold_data.shape[:3])\n",
    "    selected_linear_idx = np.flatnonzero(mask_selected)\n",
    "\n",
    "    voxel_indices_local = np.column_stack(np.unravel_index(selected_linear_idx, bold_data.shape[:3]))\n",
    "    voxel_indices = voxel_indices_local\n",
    "    selected_world_coords = nib.affines.apply_affine(anat_img.affine, voxel_indices)\n",
    "    D = cdist(selected_world_coords, selected_world_coords)\n",
    "    nonzero = D[D > 0]\n",
    "    sigma = np.median(nonzero) if nonzero.size else 1.0\n",
    "    W = np.exp(-D**2 / (2.0 * sigma**2))\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    L_smooth = csgraph.laplacian(W, normed=False)\n",
    "\n",
    "    selected_BOLD_flat = selected_BOLD_data_subset.reshape(selected_BOLD_data_subset.shape[0], -1)\n",
    "\n",
    "    return L_task, L_var, L_smooth, selected_BOLD_flat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, train_idx, trial_len): \n",
    "#     # beta_valume_clean_2d shape : (num_voxels, num_trials)\n",
    "#     # bold_data is 4D fMRI data\n",
    "#     # mask_2d is 1D boolean array indicating which voxels to exclude (all NaN in beta values)\n",
    "    \n",
    "#     beta_volume_filter_reshape = beta_valume_clean_2d.reshape(-1, beta_valume_clean_2d.shape[-1])\n",
    "#     mean_beta_filtered = np.nanmean(beta_volume_filter_reshape, axis=-1)\n",
    "#     # print(f\"Beta range: {np.nanmin(mean_beta_filtered):.2f} to {np.nanmax(mean_beta_filtered):.2f}\")\n",
    "#     L_task = np.divide(1., np.abs(mean_beta_filtered), where=mean_beta_filtered!=0)\n",
    "#     # np.save(\"L_task.npy\",L_task)\n",
    "#     # print(f\"L_task range: {np.nanmin(L_task):.2f} to {np.nanmax(L_task):.2f}\")\n",
    "\n",
    "\n",
    "#     bold_data_reshape = np.reshape(bold_data, (-1, bold_data.shape[-1]))\n",
    "#     bold_data_selected = bold_data_reshape[~mask_2d]\n",
    "#     num_trials= 90\n",
    "#     # trial_len = 9\n",
    "#     bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len))\n",
    "#     start = 0\n",
    "#     for i in range(num_trials):\n",
    "#         bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:start+trial_len]\n",
    "#         start += trial_len\n",
    "#         if start == 270 or start == 560:\n",
    "#             start += 20\n",
    "#     diff_mat = np.diff(bold_data_selected_reshape, axis=1)\n",
    "#     diff_mat_flat = diff_mat.reshape(diff_mat.shape[0], -1)\n",
    "#     L_var = np.cov(diff_mat_flat, bias=False, dtype=np.float32)\n",
    "#     L_var = (L_var + L_var.T) / 2 + 1e-6 * np.eye(L_var.shape[0])\n",
    "#     # np.save(\"L_var.npy\",L_var)\n",
    "\n",
    "\n",
    "#     crop_slices = (slice(45, 75), slice(80, 110), slice(40, 70))\n",
    "#     crop_offset = np.array([sl.start for sl in crop_slices])\n",
    "#     mask_selected = (~mask_2d).reshape(bold_data.shape[:3])\n",
    "#     selected_linear_idx = np.flatnonzero(mask_selected)\n",
    "\n",
    "#     voxel_indices_local = np.column_stack(np.unravel_index(selected_linear_idx, bold_data.shape[:3]))\n",
    "#     voxel_indices = voxel_indices_local + crop_offset\n",
    "#     selected_world_coords = nib.affines.apply_affine(anat_img.affine, voxel_indices)\n",
    "#     D = cdist(selected_world_coords, selected_world_coords)\n",
    "#     nonzero = D[D > 0]\n",
    "#     sigma = np.median(nonzero) if nonzero.size else 1.0\n",
    "#     W = np.exp(-D**2 / (2.0 * sigma**2))\n",
    "#     np.fill_diagonal(W, 0.0)\n",
    "#     L_smooth = csgraph.laplacian(W, normed=False)\n",
    "#     # np.save(\"L_smooth.npy\",L_smooth)   \n",
    "    \n",
    "#     return L_task, L_var, L_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, trial_indices=None, trial_len=9):\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "    trial_idx = np.arange(num_trials) if trial_indices is None else np.unique(np.asarray(trial_indices, int).ravel())\n",
    "\n",
    "    # ----- L_task (same idea as yours) -----\n",
    "    beta_selected = beta_valume_clean_2d[:, trial_idx]\n",
    "    counts = np.count_nonzero(np.isfinite(beta_selected), axis=-1)\n",
    "    sums = np.nansum(beta_selected, axis=-1, dtype=np.float64)\n",
    "    mean_beta = np.zeros(beta_selected.shape[0], dtype=np.float32)\n",
    "    m = counts > 0\n",
    "    mean_beta[m] = (sums[m] / counts[m]).astype(np.float32)\n",
    "    L_task = np.zeros_like(mean_beta, dtype=np.float32)\n",
    "    v = np.abs(mean_beta) > 0\n",
    "    L_task[v] = (1.0 / np.abs(mean_beta[v])).astype(np.float32)\n",
    "\n",
    "    # ----- reshape BOLD into trials -----\n",
    "    bold_data_reshape = bold_data.reshape(-1, bold_data.shape[-1])\n",
    "    bold_data_selected = bold_data_reshape[~mask_2d]         # keep voxels of interest\n",
    "    bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len), dtype=np.float32)\n",
    "    start = 0\n",
    "    for i in range(num_trials):\n",
    "        end = start + trial_len\n",
    "        if end > bold_data_selected.shape[1]:\n",
    "            raise ValueError(\"BOLD data does not contain enough timepoints for all trials\")\n",
    "        bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:end]\n",
    "        start += trial_len\n",
    "        if start == 270 or start == 560:   # your skips\n",
    "            start += 20\n",
    "    X = bold_data_selected_reshape[:, trial_idx, :]          # [Nvox, Ntrials, T]\n",
    "\n",
    "    # ----- L_var: variance of trial differences, as sparse diagonal -----\n",
    "    diff_mat = np.diff(X, axis=1)                            # [Nvox, Ntrials-1, T]\n",
    "    diff_mat = diff_mat.reshape(diff_mat.shape[0], -1)       # [Nvox, (Ntrials-1)*T]\n",
    "    diff_mat = diff_mat[:, np.all(np.isfinite(diff_mat), axis=0)]\n",
    "    if diff_mat.shape[1] < 2:\n",
    "        raise ValueError(\"Not enough finite samples to compute L_var\")\n",
    "    var_vec = np.nanvar(diff_mat, axis=1, ddof=1).astype(np.float32)  # per-voxel variance\n",
    "    L_var = sp.diags(var_vec, format='csc')                           # sparse diagonal (PSD)\n",
    "\n",
    "    # ----- L_smooth: sparse 6-neighbor Laplacian on the voxel grid -----\n",
    "    mask3d = (~mask_2d).reshape(bold_data.shape[:3])\n",
    "    idx = -np.ones(mask3d.shape, dtype=np.int64)\n",
    "    idx[mask3d] = np.arange(mask3d.sum())\n",
    "    rows, cols = [], []\n",
    "    for ax in range(3):\n",
    "        s1 = [slice(None)]*3; s2 = [slice(None)]*3\n",
    "        s1[ax] = slice(1, None); s2[ax] = slice(0, -1)\n",
    "        a, b = idx[tuple(s1)], idx[tuple(s2)]\n",
    "        m = (a != -1) & (b != -1)\n",
    "        i, j = a[m].ravel(), b[m].ravel()\n",
    "        rows.append(np.concatenate([i, j])); cols.append(np.concatenate([j, i]))\n",
    "    if rows:\n",
    "        rows, cols = np.concatenate(rows), np.concatenate(cols)\n",
    "        A = sp.coo_matrix((np.ones(rows.size, np.float32), (rows, cols)), shape=(idx.max()+1, idx.max()+1)).tocsr()\n",
    "        d = np.asarray(A.sum(axis=1)).ravel()\n",
    "        L_smooth = (sp.diags(d, 0) - A).astype(np.float32).tocsc()\n",
    "    else:\n",
    "        L_smooth = sp.csc_matrix((idx.max()+1, idx.max()+1), dtype=np.float32)\n",
    "\n",
    "    selected_BOLD_flat = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "    return L_task.astype(np.float32), L_var, L_smooth, selected_BOLD_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(w, L_task, L_var, L_smooth, alpha_var, alpha_smooth):\n",
    "    quad = (w.T @ np.diag(L_task) @ w + alpha_var * (w.T @ L_var @ w) + alpha_smooth * (w.T @ L_smooth @ w))\n",
    "    return quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_voxel_weights(L_task, L_var, L_smooth, alpha_var, alpha_smooth):\n",
    "    L_total = np.diag(L_task) + alpha_var * L_var + alpha_smooth * L_smooth\n",
    "    n = L_total.shape[0]\n",
    "    L_total = np.nan_to_num(L_total)\n",
    "    L_total = 0.5*(L_total + L_total.T) + 1e-8*np.eye(n)\n",
    "    w = cp.Variable(n, nonneg=True)\n",
    "    constraints = [cp.sum(w) == 1]\n",
    "\n",
    "    # objective = cp.Minimize(cp.quad_form(w, L_total) + alpha_sparse * cp.norm1(w))\n",
    "    objective = cp.Minimize(cp.quad_form(w, L_total))\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.OSQP, verbose=True)\n",
    "    return w.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(param_grid, beta_valume_clean_2d, bold_data, anat_img, mask_2d, trial_len):\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=0)\n",
    "    best_score = np.inf\n",
    "    best_params = None\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "\n",
    "    for a_var, a_smooth in product(*param_grid.values()):\n",
    "        fold_scores = []\n",
    "        print(f\"a_var: {a_var}, a_smooth: {a_smooth}\")\n",
    "        count = 1\n",
    "\n",
    "        for train_idx, val_idx in kf.split(np.arange(num_trials)):\n",
    "            print(f\"k-fold num: {count}\")\n",
    "            L_task_train, L_var_train, L_smooth_train, _ = calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, train_idx, trial_len)\n",
    "            w = optimize_voxel_weights(L_task_train, L_var_train, L_smooth_train, alpha_var=a_var, alpha_smooth=a_smooth)\n",
    "\n",
    "            L_task_val, L_var_val, L_smooth_val, _ = calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, val_idx, trial_len)\n",
    "\n",
    "            fold_scores.append(objective_func(w, L_task_val, L_var_val, L_smooth_val, a_var, a_smooth))\n",
    "            print(f\"fold_scores: {fold_scores}\")\n",
    "            count += 1\n",
    "\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        print(mean_score)\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = (a_var, a_smooth)\n",
    "\n",
    "    print(\"Best parameters:\", best_params, \"with CV loss:\", best_score)\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_opt_weight(selected_BOLD_data, weights, anat_img):\n",
    "    y = selected_BOLD_data.T @ weights\n",
    "    p95 = np.percentile(weights, 95)\n",
    "\n",
    "    weight_volume = np.zeros(voxel_mask.shape, dtype=np.float32)\n",
    "    weight_volume[voxel_mask] = weights.astype(np.float32)\n",
    "\n",
    "    mask = np.zeros(voxel_mask.shape, dtype=bool)\n",
    "    selected_weights = weights >= p95\n",
    "    mask[voxel_mask] = selected_weights\n",
    "    weight_volume[~mask] = 0.0\n",
    "\n",
    "    masked_weights = np.where(mask, weight_volume, np.nan)\n",
    "    weight_img = nib.Nifti1Image(masked_weights, affine=anat_img.affine)\n",
    "\n",
    "    return weight_img, masked_weights, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_var: 1.0, a_smooth: 1.0\n",
      "k-fold num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 26 06:42:50 AM: Your problem has 8563 variables, 1 constraints, and 0 parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.2                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 26 06:42:50 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Sep 26 06:42:50 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Sep 26 06:42:50 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Sep 26 06:42:50 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Sep 26 06:42:50 AM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Sep 26 06:42:50 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Sep 26 06:42:50 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Sep 26 06:42:50 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Sep 26 06:42:50 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Sep 26 06:42:50 AM: Applying reduction OSQP\n",
      "(CVXPY) Sep 26 06:42:50 AM: Finished problem compilation (took 1.875e-01 seconds).\n",
      "(CVXPY) Sep 26 06:42:50 AM: Invoking solver OSQP  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v1.0.0  -  Operator Splitting QP Solver\n",
      "              (c) The OSQP Developer Team\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 8563, constraints m = 8564\n",
      "          nnz(P) + nnz(A) = 43297\n",
      "settings: algebra = Built-in,\n",
      "          OSQPInt = 4 bytes, OSQPFloat = 8 bytes,\n",
      "          linear system solver = QDLDL v0.1.8,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive: 50 iterations),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25, duality gap: on),\n",
      "          time_limit: 1.00e+10 sec,\n",
      "          scaling: on (10 iterations), scaled_termination: off\n",
      "          warm starting: on, polishing: on, \n",
      "iter   objective    prim res   dual res   gap        rel kkt    rho         time\n",
      "   1   0.0000e+00   1.00e+00   3.94e+03  -3.94e+03   3.94e+03   1.00e-01    8.00e-03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 26 06:42:50 AM: Problem status: optimal\n",
      "(CVXPY) Sep 26 06:42:50 AM: Optimal value: 6.511e-01\n",
      "(CVXPY) Sep 26 06:42:50 AM: Compilation took 1.875e-01 seconds\n",
      "(CVXPY) Sep 26 06:42:50 AM: Solver (including time spent in interface) took 2.446e-02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50   6.5109e-01   1.61e-09   4.09e-08   4.30e-08   4.30e-08   1.00e-01    1.77e-02s\n",
      "plsh   6.5109e-01   7.20e-15   2.86e-13   2.85e-13   2.86e-13   --------    2.28e-02s\n",
      "\n",
      "status:               solved\n",
      "solution polishing:   successful\n",
      "number of iterations: 50\n",
      "optimal objective:    0.6511\n",
      "dual objective:       0.6511\n",
      "duality gap:          2.8518e-13\n",
      "primal-dual integral: 3.9379e+03\n",
      "run time:             2.28e-02s\n",
      "optimal rho estimate: 2.26e-02\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "fold_scores: [np.float64(0.6830770153343357)]\n",
      "k-fold num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 26 06:42:53 AM: Your problem has 8563 variables, 1 constraints, and 0 parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.2                                    \n",
      "===============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 26 06:42:53 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Sep 26 06:42:53 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Sep 26 06:42:53 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Sep 26 06:42:53 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Sep 26 06:42:53 AM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Sep 26 06:42:53 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Sep 26 06:42:53 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Sep 26 06:42:53 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Sep 26 06:42:53 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Sep 26 06:42:53 AM: Applying reduction OSQP\n",
      "(CVXPY) Sep 26 06:42:53 AM: Finished problem compilation (took 1.810e-01 seconds).\n",
      "(CVXPY) Sep 26 06:42:53 AM: Invoking solver OSQP  to obtain a solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v1.0.0  -  Operator Splitting QP Solver\n",
      "              (c) The OSQP Developer Team\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 8563, constraints m = 8564\n",
      "          nnz(P) + nnz(A) = 43297\n",
      "settings: algebra = Built-in,\n",
      "          OSQPInt = 4 bytes, OSQPFloat = 8 bytes,\n",
      "          linear system solver = QDLDL v0.1.8,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive: 50 iterations),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25, duality gap: on),\n",
      "          time_limit: 1.00e+10 sec,\n",
      "          scaling: on (10 iterations), scaled_termination: off\n",
      "          warm starting: on, polishing: on, \n",
      "iter   objective    prim res   dual res   gap        rel kkt    rho         time\n",
      "   1   0.0000e+00   1.00e+00   3.41e+03  -3.41e+03   3.41e+03   1.00e-01    7.92e-03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 26 06:42:53 AM: Problem status: optimal\n",
      "(CVXPY) Sep 26 06:42:53 AM: Optimal value: 6.719e-01\n",
      "(CVXPY) Sep 26 06:42:53 AM: Compilation took 1.810e-01 seconds\n",
      "(CVXPY) Sep 26 06:42:53 AM: Solver (including time spent in interface) took 2.453e-02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50   6.7190e-01   1.58e-09   3.36e-08   3.57e-08   3.57e-08   1.00e-01    1.78e-02s\n",
      "plsh   6.7190e-01   7.05e-15   2.44e-13   2.41e-13   2.44e-13   --------    2.29e-02s\n",
      "\n",
      "status:               solved\n",
      "solution polishing:   successful\n",
      "number of iterations: 50\n",
      "optimal objective:    0.6719\n",
      "dual objective:       0.6719\n",
      "duality gap:          2.4138e-13\n",
      "primal-dual integral: 3.4109e+03\n",
      "run time:             2.29e-02s\n",
      "optimal rho estimate: 2.52e-02\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "fold_scores: [np.float64(0.6830770153343357), np.float64(0.6615867410938843)]\n",
      "0.67233187821411\n",
      "Best parameters: (1.0, 1.0) with CV loss: 0.67233187821411\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"alpha_var\":   [1.0],\n",
    "    \"alpha_smooth\":[1.0]}\n",
    "\n",
    "import scipy.sparse as sp\n",
    "trial_len = 9\n",
    "best_params, best_score = calculate_weight(param_grid, beta_valume_clean_2d, bold_data, anat_img, mask_2d, trial_len)\n",
    "\n",
    "# L_task, L_var, L_smooth, selected_BOLD_data = calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, None, trial_len)\n",
    "# weights = optimize_voxel_weights(L_task, L_var, L_smooth, alpha_var=best_params[0], alpha_smooth=best_params[1])\n",
    "# weight_img, masked_weights, y = select_opt_weight(selected_BOLD_data, weights, active_low_var_voxels.astype(bool), affine)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_task, L_var, L_smooth, selected_BOLD_data = calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, None, trial_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = optimize_voxel_weights(L_task, L_var, L_smooth, alpha_var=best_params[0], alpha_smooth=best_params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights.shape, np.max(weights), np.min(weights), np.sum(weights), np.median(weights), np.mean(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = selected_BOLD_data.T @ weights\n",
    "p95 = np.percentile(weights, 95)\n",
    "selected_weights = weights >= p95\n",
    "\n",
    "print(p95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(selected_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_img, masked_weights, y = select_opt_weight(selected_BOLD_data, weights, anat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fetch_atlas_harvard_oxford] Dataset found in /home/zkavian/nilearn_data/fsl\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets, image, masking\n",
    "\n",
    "ho = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm', symmetric_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Background',\n",
       " 'Left Frontal Pole',\n",
       " 'Right Frontal Pole',\n",
       " 'Left Insular Cortex',\n",
       " 'Right Insular Cortex',\n",
       " 'Left Superior Frontal Gyrus',\n",
       " 'Right Superior Frontal Gyrus',\n",
       " 'Left Middle Frontal Gyrus',\n",
       " 'Right Middle Frontal Gyrus',\n",
       " 'Left Inferior Frontal Gyrus, pars triangularis',\n",
       " 'Right Inferior Frontal Gyrus, pars triangularis',\n",
       " 'Left Inferior Frontal Gyrus, pars opercularis',\n",
       " 'Right Inferior Frontal Gyrus, pars opercularis',\n",
       " 'Left Precentral Gyrus',\n",
       " 'Right Precentral Gyrus',\n",
       " 'Left Temporal Pole',\n",
       " 'Right Temporal Pole',\n",
       " 'Left Superior Temporal Gyrus, anterior division',\n",
       " 'Right Superior Temporal Gyrus, anterior division',\n",
       " 'Left Superior Temporal Gyrus, posterior division',\n",
       " 'Right Superior Temporal Gyrus, posterior division',\n",
       " 'Left Middle Temporal Gyrus, anterior division',\n",
       " 'Right Middle Temporal Gyrus, anterior division',\n",
       " 'Left Middle Temporal Gyrus, posterior division',\n",
       " 'Right Middle Temporal Gyrus, posterior division',\n",
       " 'Left Middle Temporal Gyrus, temporooccipital part',\n",
       " 'Right Middle Temporal Gyrus, temporooccipital part',\n",
       " 'Left Inferior Temporal Gyrus, anterior division',\n",
       " 'Right Inferior Temporal Gyrus, anterior division',\n",
       " 'Left Inferior Temporal Gyrus, posterior division',\n",
       " 'Right Inferior Temporal Gyrus, posterior division',\n",
       " 'Left Inferior Temporal Gyrus, temporooccipital part',\n",
       " 'Right Inferior Temporal Gyrus, temporooccipital part',\n",
       " 'Left Postcentral Gyrus',\n",
       " 'Right Postcentral Gyrus',\n",
       " 'Left Superior Parietal Lobule',\n",
       " 'Right Superior Parietal Lobule',\n",
       " 'Left Supramarginal Gyrus, anterior division',\n",
       " 'Right Supramarginal Gyrus, anterior division',\n",
       " 'Left Supramarginal Gyrus, posterior division',\n",
       " 'Right Supramarginal Gyrus, posterior division',\n",
       " 'Left Angular Gyrus',\n",
       " 'Right Angular Gyrus',\n",
       " 'Left Lateral Occipital Cortex, superior division',\n",
       " 'Right Lateral Occipital Cortex, superior division',\n",
       " 'Left Lateral Occipital Cortex, inferior division',\n",
       " 'Right Lateral Occipital Cortex, inferior division',\n",
       " 'Left Intracalcarine Cortex',\n",
       " 'Right Intracalcarine Cortex',\n",
       " 'Left Frontal Medial Cortex',\n",
       " 'Right Frontal Medial Cortex',\n",
       " 'Left Juxtapositional Lobule Cortex (formerly Supplementary Motor Cortex)',\n",
       " 'Right Juxtapositional Lobule Cortex (formerly Supplementary Motor Cortex)',\n",
       " 'Left Subcallosal Cortex',\n",
       " 'Right Subcallosal Cortex',\n",
       " 'Left Paracingulate Gyrus',\n",
       " 'Right Paracingulate Gyrus',\n",
       " 'Left Cingulate Gyrus, anterior division',\n",
       " 'Right Cingulate Gyrus, anterior division',\n",
       " 'Left Cingulate Gyrus, posterior division',\n",
       " 'Right Cingulate Gyrus, posterior division',\n",
       " 'Left Precuneous Cortex',\n",
       " 'Right Precuneous Cortex',\n",
       " 'Left Cuneal Cortex',\n",
       " 'Right Cuneal Cortex',\n",
       " 'Left Frontal Orbital Cortex',\n",
       " 'Right Frontal Orbital Cortex',\n",
       " 'Left Parahippocampal Gyrus, anterior division',\n",
       " 'Right Parahippocampal Gyrus, anterior division',\n",
       " 'Left Parahippocampal Gyrus, posterior division',\n",
       " 'Right Parahippocampal Gyrus, posterior division',\n",
       " 'Left Lingual Gyrus',\n",
       " 'Right Lingual Gyrus',\n",
       " 'Left Temporal Fusiform Cortex, anterior division',\n",
       " 'Right Temporal Fusiform Cortex, anterior division',\n",
       " 'Left Temporal Fusiform Cortex, posterior division',\n",
       " 'Right Temporal Fusiform Cortex, posterior division',\n",
       " 'Left Temporal Occipital Fusiform Cortex',\n",
       " 'Right Temporal Occipital Fusiform Cortex',\n",
       " 'Left Occipital Fusiform Gyrus',\n",
       " 'Right Occipital Fusiform Gyrus',\n",
       " 'Left Frontal Opercular Cortex',\n",
       " 'Right Frontal Opercular Cortex',\n",
       " 'Left Central Opercular Cortex',\n",
       " 'Right Central Opercular Cortex',\n",
       " 'Left Parietal Opercular Cortex',\n",
       " 'Right Parietal Opercular Cortex',\n",
       " 'Left Planum Polare',\n",
       " 'Right Planum Polare',\n",
       " \"Left Heschl's Gyrus (includes H1 and H2)\",\n",
       " \"Right Heschl's Gyrus (includes H1 and H2)\",\n",
       " 'Left Planum Temporale',\n",
       " 'Right Planum Temporale',\n",
       " 'Left Supracalcarine Cortex',\n",
       " 'Right Supracalcarine Cortex',\n",
       " 'Left Occipital Pole',\n",
       " 'Right Occipital Pole']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ho['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
