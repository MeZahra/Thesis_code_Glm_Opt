{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe3135c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from nilearn import plotting\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse import csgraph\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.ticker as mticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b44b4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil, os\n",
    "p = psutil.Process(os.getpid())\n",
    "p.cpu_affinity({20,21,22,23,24,25,26,27,28,29})   # use only core 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b8b86",
   "metadata": {},
   "source": [
    "Loading Datasets and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from os.path import join\n",
    "\n",
    "ses = 1\n",
    "sub = '07'\n",
    "run = 1\n",
    "\n",
    "base_path = '/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives'\n",
    "\n",
    "# Load images without forcing full data into memory when not needed\n",
    "anat_path = f'{base_path}/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain.nii.gz'\n",
    "anat_img = nib.load(anat_path) \n",
    "print(anat_img.shape)\n",
    "\n",
    "data_name = f'sub-pd0{sub}_ses-{ses}_run-{run}_task-mv_bold_corrected_smoothed_reg.nii.gz'\n",
    "BOLD_path_org = join(base_path, f'sub-pd0{sub}', f'ses-{ses}', 'func', data_name)\n",
    "bold_img = nib.load(BOLD_path_org)\n",
    "bold_data = bold_img.get_fdata()\n",
    "\n",
    "mask_base = f'{base_path}/sub-pd0{sub}/ses-{ses}/anat'\n",
    "\n",
    "brain_mask_path = f'{mask_base}/sub-pd0{sub}_ses-{ses}_T1w_brain_mask.nii.gz'\n",
    "brain_mask_img = nib.load(brain_mask_path)\n",
    "back_mask = brain_mask_img.get_fdata()\n",
    "\n",
    "csf_path = f'{mask_base}/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_0.nii.gz'\n",
    "csf_mask = nib.load(csf_path).get_fdata()\n",
    "\n",
    "wm_path = f'{mask_base}/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_1.nii.gz'\n",
    "white_mask = nib.load(wm_path).get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6a96e",
   "metadata": {},
   "source": [
    "Apply Masks on Bold Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec92f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_mask_data = back_mask > 0\n",
    "csf_mask_data = csf_mask > 0\n",
    "white_mask_data = white_mask > 0.5\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "nonzero_mask = np.where(mask)\n",
    "\n",
    "white_mask_flat = white_mask_data[nonzero_mask]\n",
    "keep_voxels = ~white_mask_flat\n",
    "\n",
    "bold_flat = bold_data[nonzero_mask]\n",
    "masked_bold = bold_flat[keep_voxels]\n",
    "\n",
    "masked_coords = tuple(ax[keep_voxels] for ax in nonzero_mask)\n",
    "\n",
    "print(f\"number of selected voxels after masking: {masked_bold.shape[0]/math.prod(bold_data.shape[:3])*100:.2f}%\")\n",
    "print('bold_data masked shape:', masked_bold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0b5bc",
   "metadata": {},
   "source": [
    "Plot voxels not in CSF and Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "314a367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "# selected_mask[masked_coords] = 1\n",
    "# selected_mask_img = nib.Nifti1Image(selected_mask, brain_mask_img.affine, brain_mask_img.header)\n",
    "\n",
    "# view = plotting.view_img(\n",
    "#     selected_mask_img,\n",
    "#     bg_img=anat_img,\n",
    "#     cmap='jet',\n",
    "#     title='Selected voxels on anatomy',\n",
    "# )\n",
    "# view.save_as_html(\"Selected voxels on anatomy.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3fe2bb",
   "metadata": {},
   "source": [
    "Remove voxels in CSF & brain mask from the bold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5187e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 90\n",
    "trial_len = 9\n",
    "masked_bold = masked_bold.astype(np.float32)\n",
    "num_voxels, num_timepoints = masked_bold.shape\n",
    "bold_data_reshape = np.full((num_voxels, num_trials, trial_len), np.nan, dtype=np.float32)\n",
    "\n",
    "start = 0\n",
    "for i in range(num_trials):\n",
    "    end = start + trial_len\n",
    "    if end > num_timepoints:\n",
    "        raise ValueError(\"Masked BOLD data does not contain enough timepoints for all trials\")\n",
    "    bold_data_reshape[:, i, :] = masked_bold[:, start:end]\n",
    "    start += trial_len\n",
    "    if start in (270, 560):\n",
    "        start += 20  # skip discarded timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6edd32c",
   "metadata": {},
   "source": [
    "Load Beta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_dict = np.load(f'TYPED_FITHRF_GLMDENOISE_RR_sub{sub}.npy', allow_pickle=True).item()\n",
    "beta_glm = glm_dict['betasmd']\n",
    "beta_run1, beta_run2 = beta_glm[:,0,0,:90], beta_glm[:,0,0,90:]\n",
    "\n",
    "if run == 1:\n",
    "    beta = beta_run1[keep_voxels]\n",
    "else:\n",
    "    beta = beta_run2[keep_voxels]\n",
    "print(\"Beta Range:[\", np.nanmin(beta), np.nanmax(beta), \"], Mean: \", np.nanmean(beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9845485",
   "metadata": {},
   "source": [
    "check how many trials for each voxel have outlier beta (shows my previous method is incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d740bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_thr, upper_thr = np.nanpercentile(beta, [1, 99])\n",
    "# print(f'low_thr: {lower_thr:.2f}, high_thr: {upper_thr:.2f}') #low_thr: -4.64, high_thr: 4.60\n",
    "# beta_extreme_mask = np.logical_or(beta < lower_thr, beta > upper_thr)\n",
    "# voxels_with_extreme_beta = np.any(beta_extreme_mask, axis=1)\n",
    "\n",
    "# print(f\"percentage of voxels with extreme beta values: {np.sum(voxels_with_extreme_beta)/beta.shape[0]*100:.2f}%\")\n",
    "\n",
    "# mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "# mask &= ~white_mask_data\n",
    "# nonzero_mask = np.where(mask)\n",
    "\n",
    "# clean_beta = beta[~voxels_with_extreme_beta]\n",
    "# print('clean_beta shape:', clean_beta.shape)\n",
    "\n",
    "# # This figure is related to my previous calculation (remove voxels even if they have one trial)\n",
    "# tmp = np.sum(beta_extreme_mask[voxels_with_extreme_beta, :], axis=1)\n",
    "# plt.hist(tmp)\n",
    "# plt.xlabel('Num_trials')\n",
    "# plt.ylabel(\"voxel count\")\n",
    "# plt.title('Trial-level Outlier Counts in Voxels with Extreme Beta')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ece6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure Mean and Var (Beta)\n",
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(np.mean(beta, axis=1))\n",
    "# axs[0].set_title('Mean')\n",
    "# axs[1].hist(np.var(beta, axis=1))\n",
    "# axs[1].set_title('Var')\n",
    "# plt.suptitle('Original Beta')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af429613",
   "metadata": {},
   "source": [
    "Normalize beta value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee127200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outlier beta after normalization\n",
    "med = np.nanmedian(beta, keepdims=True)\n",
    "mad = np.nanmedian(np.abs(beta - med), keepdims=True)\n",
    "scale = 1.4826 * np.maximum(mad, 1e-9)    \n",
    "beta_norm = (beta - med) / scale      \n",
    "thr = np.nanpercentile(np.abs(beta_norm), 99.9)\n",
    "outlier_mask = np.abs(beta_norm) > thr      \n",
    "print(f\"{np.sum(np.any(outlier_mask, axis=1))/beta.shape[0]*100:.2f}% voxels with at least one outlier beta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8caf4",
   "metadata": {},
   "source": [
    "plot how many trials of each voxels are outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28596ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.sum(outlier_mask, axis=1)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(data, bins=np.arange(data.min(), data.max() + 1), color=\"0.4\")\n",
    "# ax.set_xlabel(\"Num Trials\")\n",
    "# ax.set_ylabel(\"Num Voxels\")\n",
    "\n",
    "# axin = inset_axes(ax, width=1.2, height=1.2, bbox_to_anchor=(20, 300000), bbox_transform=ax.transData, loc='center', borderpad=1)\n",
    "# axin.hist(data, bins=np.arange(10, 45), range=(10, 45), color=\"tab:orange\")\n",
    "# axin.set_xlim(10, 45)\n",
    "# axin.tick_params(labelsize=7)\n",
    "# axin.set_title(\"Range 10-45\", fontsize=8)\n",
    "\n",
    "# axin1 = inset_axes(ax, width=1.2, height=1.2, bbox_to_anchor=(60, 300000), bbox_transform=ax.transData, loc='center', borderpad=1)\n",
    "# axin1.hist(data, bins=np.arange(45, 90), range=(45, 90), color=\"tab:red\")\n",
    "# axin1.set_xlim(45, 90)\n",
    "# axin1.tick_params(labelsize=7)\n",
    "# axin1.set_title(\"Range 45, 90\", fontsize=8)\n",
    "\n",
    "# fig.suptitle(\"Outlier trials counts for each voxels\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad6407",
   "metadata": {},
   "source": [
    "NaN trials with extremely different beta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8771142",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_beta = beta.copy()\n",
    "voxel_outlier_fraction = np.mean(outlier_mask, axis=1)\n",
    "valid_voxels = voxel_outlier_fraction <= 0.5\n",
    "clean_beta[~valid_voxels] = np.nan\n",
    "clean_beta[np.logical_and(outlier_mask, valid_voxels[:, None])] = np.nan\n",
    "keeped_mask = ~np.all(np.isnan(clean_beta), axis=1)\n",
    "clean_beta = clean_beta[keeped_mask]\n",
    "keeped_indices = np.flatnonzero(keeped_mask)\n",
    "\n",
    "bold_data_reshape[~valid_voxels, :, :] = np.nan\n",
    "# trial_outliers = np.logical_and(outlier_mask, valid_voxels[:, None])\n",
    "# if np.any(trial_outliers):\n",
    "#     vox_idx, trial_idx = np.where(trial_outliers)\n",
    "#     bold_data_reshape[vox_idx, trial_idx, :] = np.nan\n",
    "bold_data_reshape = bold_data_reshape[keeped_mask]\n",
    "\n",
    "print(f\"{(beta.shape[0]-clean_beta.shape[0])/beta.shape[0]*100}% of voxels have more than 50% outlier trials\")\n",
    "print('Clean BOLD reshape shape:', bold_data_reshape.shape)\n",
    "print(f\"Clean beta range: {np.nanmin(clean_beta):.2f}, {np.nanmax(clean_beta):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8a17f",
   "metadata": {},
   "source": [
    "Plot Beta and clean_beta on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca5cb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collapse betas to single value per voxel (choose the summary you need)\n",
    "# beta_summary = np.nanmean(beta, axis=1)\n",
    "# clean_beta_summary = np.nanmean(clean_beta, axis=1)\n",
    "\n",
    "# # Allocate full-brain volumes\n",
    "# beta_map = np.full(bold_data.shape[:3], np.nan, dtype=np.float32)\n",
    "# beta_map[masked_coords] = beta_summary\n",
    "\n",
    "# clean_masked_coords = tuple(coord[keeped_mask] for coord in masked_coords)\n",
    "# clean_beta_map = np.full(bold_data.shape[:3], np.nan, dtype=np.float32)\n",
    "# clean_beta_map[clean_masked_coords] = clean_beta_summary\n",
    "\n",
    "# beta_img_stat = nib.Nifti1Image(beta_map, bold_img.affine)\n",
    "# clean_beta_img_stat = nib.Nifti1Image(clean_beta_map, bold_img.affine)\n",
    "\n",
    "# beta_img_res = resample_to_img(beta_img_stat, anat_img, interpolation=\"linear\")\n",
    "# clean_beta_img_res = resample_to_img(clean_beta_img_stat, anat_img, interpolation=\"linear\")\n",
    "\n",
    "# finite_vals = clean_beta_map[np.isfinite(clean_beta_map)]\n",
    "# vmin, vmax = finite_vals.min(), finite_vals.max()\n",
    "# print(vmin, vmax)\n",
    "\n",
    "# view = plotting.view_img(\n",
    "#     beta_img_stat,\n",
    "#     bg_img=anat_img,\n",
    "#     threshold=0,\n",
    "#     cmap='jet',\n",
    "#     symmetric_cmap=False,\n",
    "#     vmax=np.nanmax(beta_map),\n",
    "#     vmin=-np.nanmin(beta_map),\n",
    "#     title=\"Beta (mean across trials)\",\n",
    "# )\n",
    "\n",
    "# view.save_as_html(\"Beta (mean across trials).html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b557844",
   "metadata": {},
   "source": [
    "Plot beta and clean beta histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee145ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = clean_beta.ravel()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.hist(tmp, density=True, bins=100)\n",
    "# ax.set_title('Cleaned beta')\n",
    "# ax.set_xlabel('beta')\n",
    "# ax.set_ylabel('density')\n",
    "# ax.set_xlim(np.nanmin(tmp), np.nanmax(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38864942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import numpy as np\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 7))\n",
    "# tmp = beta.ravel()\n",
    "\n",
    "# counts, bins, _ = ax.hist(tmp, bins=100, density=True, color='C0', alpha=0.85, edgecolor='none')\n",
    "# ax.set_title('All beta')\n",
    "# ax.set_xlabel('beta')\n",
    "# ax.set_ylabel('density')\n",
    "\n",
    "# ranges = [(-500,-20),(-1000,-500),(-2000,-1000), (100, 5000), (5000, 10000), (10000, 15000), (15000, 20000),(-20,20)]\n",
    "# colors = ['C7','C6','C5','C1', 'C2', 'C3', 'C4','C8']\n",
    "# positions = [\n",
    "#     [0.3, 0.5, 0.1, 0.10],\n",
    "#     [0.5, 0.5, 0.1, 0.10],\n",
    "#     [0.8, 0.5, 0.1, 0.10],\n",
    "#     [0.3, 0.2, 0.1, 0.10],\n",
    "#     [0.3, 0.7, 0.1, 0.10],\n",
    "#     [0.8, 0.2, 0.1, 0.10],\n",
    "#     [0.8, 0.7, 0.1, 0.10],\n",
    "#     [0.5, 0.2, 0.2, 0.20]\n",
    "# ]\n",
    "\n",
    "# ymax = counts.max()\n",
    "\n",
    "# for (lo, hi), color, pos in zip(ranges, colors, positions):\n",
    "#     # rect = patches.Rectangle((lo, 0), hi - lo, ymax, linewidth=1.5,\n",
    "#     #                          edgecolor=color, facecolor='none', linestyle='--')\n",
    "#     # ax.add_patch(rect)\n",
    "\n",
    "#     axins = fig.add_axes(pos)\n",
    "#     mask = (tmp >= lo) & (tmp < hi)\n",
    "#     axins.hist(tmp[mask], bins=np.linspace(lo, hi, 20), density=True,\n",
    "#                color=color, alpha=0.85, edgecolor='none')\n",
    "#     axins.set_xlim(lo, hi)\n",
    "#     # axins.set_ylim(0, ymax)\n",
    "#     axins.set_title(f'{lo:.0f}–{hi:.0f}', fontsize=9)\n",
    "#     axins.tick_params(axis='both', labelsize=7)\n",
    "#     # axins.set_yticks([])\n",
    "\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a892e2b",
   "metadata": {},
   "source": [
    "Remove voxels with most of trials have bad beta value, interpolate rest of the beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect how many trials are bad for selected voxels\n",
    "# beta_clean = beta.copy()\n",
    "# trials = np.arange(beta.shape[1])\n",
    "# voxel_outlier_fraction = np.sum(outlier_mask, axis=1)/outlier_mask.shape[1]*100\n",
    "# valid_voxels = voxel_outlier_fraction <= 50\n",
    "# beta_clean[~valid_voxels] = np.nan \n",
    "\n",
    "# # save the selected voxels indices for later\n",
    "# keeped_voxels_mask = ~np.all(np.isnan(beta_clean), axis=1)\n",
    "# keeped_voxels_indices = np.flatnonzero(keeped_voxels_mask)\n",
    "\n",
    "# ## Measure Mean and Var (Beta)\n",
    "# # fig, axs = plt.subplots(1,2)\n",
    "# # axs[0].hist(np.mean(beta_clean, axis=1))\n",
    "# # axs[0].set_title('Mean')\n",
    "# # axs[1].hist(np.var(beta_clean, axis=1))\n",
    "# # axs[1].set_title('Var')\n",
    "# # plt.suptitle('After removing voxels (with 50% or higher trials with high beta)')\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()\n",
    "\n",
    "# # interpolate beta value for voxels which have less than 50% of trials as bad\n",
    "# orig_outlier = []\n",
    "# intrp_outlier = []\n",
    "# for v in np.flatnonzero(valid_voxels):\n",
    "#     mask = outlier_mask[v]\n",
    "#     if not mask.any():\n",
    "#         continue\n",
    "#     good = ~mask\n",
    "#     orig_outlier.append(beta[v, mask])\n",
    "#     beta_clean[v, mask] = np.interp(trials[mask], trials[good], beta[v, good])\n",
    "#     intrp_outlier.append(beta_clean[v, mask])\n",
    "\n",
    "# # remove voxels that have more than 50% of trials bad beta value\n",
    "# beta_clean1 = beta_clean[~np.all(np.isnan(beta_clean), axis=1)]\n",
    "# print(f\"{(beta_clean.shape[0]-beta_clean1.shape[0])/beta_clean.shape[0]*100:.3f}% voxels have more than 50% trials with outlier\")\n",
    "# clean_beta = beta_clean1\n",
    "# clean_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure Mean and Var (Beta)\n",
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(np.mean(clean_beta, axis=1))\n",
    "# axs[0].set_title('Mean')\n",
    "# axs[1].hist(np.var(clean_beta, axis=1))\n",
    "# axs[1].set_title('Var')\n",
    "# plt.suptitle('After Interpolation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure Skewness and Kurtosis\n",
    "# from scipy.stats import skew\n",
    "# from scipy.stats import kurtosis\n",
    "\n",
    "# skew_value = skew(clean_beta, axis=1)\n",
    "# kurt_value = kurtosis(clean_beta, axis=1)\n",
    "\n",
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs[0].hist(skew_value)\n",
    "# axs[0].set_title('Skewness')\n",
    "# axs[1].hist(kurt_value)\n",
    "# axs[1].set_title('kurtosis ')\n",
    "# plt.suptitle('After Interpolation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compare bold and beta variance \n",
    "# clean_bold = masked_bold[keeped_voxels_mask] \n",
    "# num_trials = 90\n",
    "# trial_len = 9\n",
    "# clean_bold_reshape = np.zeros((clean_bold.shape[0], num_trials, trial_len))\n",
    "# start = 0\n",
    "\n",
    "# for i in range(num_trials):\n",
    "#         end = start + trial_len\n",
    "#         clean_bold_reshape[:, i, :] = clean_bold[:, start:end]\n",
    "#         start += trial_len\n",
    "#         if start == 270 or start == 560:   # your skips\n",
    "#             start += 20\n",
    "\n",
    "# bold_var = np.mean(np.var(clean_bold_reshape, axis=1), axis=-1)\n",
    "# beta_var = np.var(clean_beta, axis=-1)\n",
    "\n",
    "# np.corrcoef(bold_var, beta_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39695ed5",
   "metadata": {},
   "source": [
    "Plot beta, clean_beta, interpolated beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a754d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hist_with_zoom_ranges(x, fig_title, zoom_ranges, main_bins=200, inset_bins=60, density=False):\n",
    "#     fig, ax = plt.subplots(figsize=(9,7))\n",
    "#     ax.hist(x, bins=main_bins, density=density, color='C0', alpha=0.85, edgecolor='none')\n",
    "#     ax.set_title(fig_title)\n",
    "#     ax.set_xlabel('beta')\n",
    "#     ax.set_ylabel('density' if density else 'count')\n",
    "\n",
    "#     inset_data = []\n",
    "#     for (lo, hi) in zoom_ranges:\n",
    "#         xin = x[(x >= lo) & (x <= hi)]\n",
    "#         counts, edges = np.histogram(xin, bins=inset_bins, range=(lo, hi), density=density)\n",
    "#         inset_data.append((lo, hi, xin, edges, counts))\n",
    "\n",
    "#     boxes = [(0.08, 0.08, 0.4, 0.34),\n",
    "#              (0.2, 0.3, 0.4, 0.4),\n",
    "#              (0.64, 0.08, 0.4, 0.34)]\n",
    "\n",
    "#     for (left, bottom, w, h), (lo, hi, xin, edges, counts) in zip(boxes, inset_data):\n",
    "#         axins = inset_axes(ax, width=f\"{w*100:.0f}%\", height=f\"{h*100:.0f}%\", bbox_to_anchor=(left, bottom, w, h), bbox_transform=ax.transAxes,\n",
    "#             loc='upper left', borderpad=0.8)\n",
    "\n",
    "#         if xin.size:\n",
    "#             axins.hist(xin, bins=edges, density=density, color='C0', alpha=0.95, edgecolor='none')\n",
    "#         else:\n",
    "#             axins.text(0.5, 0.5, 'no data', ha='center', va='center', fontsize=8, transform=axins.transAxes)\n",
    "\n",
    "#         axins.set_xlim(lo, hi)\n",
    "\n",
    "#         if counts.size:\n",
    "#             ymax = counts.max()\n",
    "#             axins.set_ylim(0, ymax * 1.1)\n",
    "#         else:\n",
    "#             axins.set_ylim(0, 1)\n",
    "\n",
    "#         axins.set_title(f\"[{lo}, {hi}]\", fontsize=9)\n",
    "#         axins.tick_params(labelsize=8)\n",
    "\n",
    "#         pp, p1, p2 = mark_inset(ax, axins, loc1=3, loc2=4, fc='none', ec='none')\n",
    "#         pp.set_visible(False)\n",
    "#         for con in (p1, p2):\n",
    "#             con.set_color('0.4')\n",
    "#             con.set_linewidth(1.2)\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     return fig, ax\n",
    "\n",
    "\n",
    "# x = np.concatenate(orig_outlier)\n",
    "# hist_with_zoom_ranges(x, 'Original Beta (for selected voxels)', ((-1500,-1000), (-100,100), (1000,2000)))\n",
    "# plt.show()\n",
    "\n",
    "# # x = np.concatenate(intrp_outlier)\n",
    "# # hist_with_zoom_ranges(x, 'Interpolated Beta (for selected voxels)')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248da8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before = np.concatenate(orig_outlier)     \n",
    "# after  = np.concatenate(intrp_outlier)  \n",
    "\n",
    "# n_bins = 200\n",
    "# xmin, xmax = np.percentile(before, [0.1, 99.9])\n",
    "# edges = np.linspace(xmin, xmax, n_bins + 1)\n",
    "# b_counts, _ = np.histogram(before, bins=edges)\n",
    "# a_counts, _ = np.histogram(after,   bins=edges)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(15, 4), gridspec_kw={\"wspace\": 0.3})\n",
    "# axs[0].hist(before, bins=edges, alpha=0.45, label='Before', color='C0')\n",
    "# axs[0].hist(after,   bins=edges, alpha=0.45, label='After',  color='C1')\n",
    "# axs[0].set_title('Beta bafore & after interpolation')\n",
    "# axs[0].set_ylabel('count')\n",
    "# axs[0].legend()\n",
    "\n",
    "# centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "# delta = a_counts - b_counts\n",
    "# axs[1].bar(centers, delta, width=np.diff(edges), align='center', color='C2', alpha=0.8)\n",
    "# axs[1].axhline(0, color='0.3', lw=1)\n",
    "# axs[1].set_title('Per-bin change (After − Before)')\n",
    "# axs[1].set_xlabel('beta')\n",
    "# axs[1].set_ylabel('Δ count')\n",
    "\n",
    "# zoom_ranges = [(-800, -250), (250, 1000)]\n",
    "# positions = [(0.1, 0.4, 0.5, 0.5),   \n",
    "#              (0.6, 0.4, 0.5, 0.5)]   \n",
    "\n",
    "# for (lo, hi), (lx, ly, lw, lh) in zip(zoom_ranges, positions):\n",
    "#     axins = inset_axes(axs[1],\n",
    "#                        width=f\"{lw*100:.0f}%\",\n",
    "#                        height=f\"{lh*100:.0f}%\",\n",
    "#                        bbox_to_anchor=(lx, ly, lw, lh),\n",
    "#                        bbox_transform=axs[1].transAxes,\n",
    "#                        loc='upper left',\n",
    "#                        borderpad=0.8)\n",
    "#     mask = (centers >= lo) & (centers <= hi)\n",
    "#     axins.bar(centers[mask], delta[mask], width=np.diff(edges)[mask], align='center', color='C2', alpha=0.8)\n",
    "#     axins.axhline(0, color='0.3', lw=1)\n",
    "#     axins.set_xlim(lo, hi)\n",
    "#     axins.set_title(f\"[{lo},{hi}]\", fontsize=8)\n",
    "#     axins.tick_params(labelsize=7)\n",
    "\n",
    "#     pp, p1, p2 = mark_inset(axs[1], axins, loc1=3, loc2=4, fc='none', ec='none')\n",
    "#     pp.set_visible(False)\n",
    "#     for con in (p1, p2):\n",
    "#         con.set_color('0.4')\n",
    "#         con.set_linewidth(1.2)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(clean_beta.ravel())\n",
    "# plt.xlabel(\"Beta\")\n",
    "# plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bfa28",
   "metadata": {},
   "source": [
    "Plot outlier voxel on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme_volume = np.zeros(bold_img.shape[:3], dtype=np.float32)\n",
    "# nonzero_mask_kept = tuple(axis[keep_voxels] for axis in nonzero_mask)\n",
    "\n",
    "# extreme_volume[nonzero_mask_kept] = (~valid_voxels).astype(np.float32)\n",
    "# extreme_img = nib.Nifti1Image(extreme_volume, bold_img.affine, bold_img.header)\n",
    "# extreme_img = resample_to_img(extreme_img, anat_img, interpolation='nearest')\n",
    "# view = plotting.view_img(extreme_img, bg_img=anat_img, cmap='autumn', symmetric_cmap=False, threshold=0.5, vmax=1, opacity=0.9, title='Voxels with Extreme Betas')\n",
    "# view\n",
    "# view.save_as_html(file_name=f'rejected_voxels_sub{sub}_ses{ses}_run{run}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a1c54",
   "metadata": {},
   "source": [
    "Apply t-test and FDR, detect & remove non-active voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample t-test against 0\n",
    "tvals, pvals = ttest_1samp(clean_beta, popmean=0, axis=1, nan_policy='omit')\n",
    "\n",
    "# FDR correction\n",
    "tested = np.isfinite(pvals)\n",
    "alpha=0.05\n",
    "rej, q, _, _ = multipletests(pvals[tested], alpha=alpha, method='fdr_bh')\n",
    "\n",
    "n_voxel = clean_beta.shape[0]\n",
    "qvals  = np.full(n_voxel, np.nan)\n",
    "reject = np.zeros(n_voxel, dtype=bool)\n",
    "reject[tested] = rej\n",
    "qvals[tested]  = q\n",
    "\n",
    "# reject non-active voxels\n",
    "clean_active_beta = clean_beta[reject]\n",
    "clean_active_idx = keeped_indices[reject]\n",
    "clean_active_bold = bold_data_reshape[reject]\n",
    "print('Active BOLD shape:', clean_active_bold.shape)\n",
    "print(f\"{clean_active_beta.shape[0]/clean_beta.shape[0]*100:.2f}% of voxels are active at FDR q<{alpha}\")\n",
    "clean_active_beta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1721c10",
   "metadata": {},
   "source": [
    "Plot the beta hist again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cca52766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = clean_active_beta.ravel()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.hist(tmp, density=True, bins=100)\n",
    "# ax.set_title('Cleaned beta')\n",
    "# ax.set_xlabel('beta')\n",
    "# ax.set_ylabel('density')\n",
    "# ax.set_xlim(np.nanmin(tmp), np.nanmax(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072b8d3",
   "metadata": {},
   "source": [
    "Create 3-D beta dataset to use it for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = beta.shape[-1]\n",
    "clean_active_volume = np.full(bold_data.shape[:3]+(num_trials,), np.nan)\n",
    "active_coords = tuple(coord[clean_active_idx] for coord in masked_coords)\n",
    "clean_active_volume[active_coords[0], active_coords[1], active_coords[2], :] = clean_active_beta\n",
    "clean_active_volume.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec597c5",
   "metadata": {},
   "source": [
    "Map mean beta for active voxels back into anatomical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_beta_volume = np.nanmean(clean_active_volume, axis=-1)\n",
    "# mean_beta_img = nib.Nifti1Image(mean_beta_volume, bold_img.affine, bold_img.header)\n",
    "# # mean_beta_img = resample_to_img(mean_beta_img, anat_img, interpolation='linear')\n",
    "\n",
    "# active_beta_view = plotting.view_img(mean_beta_img, bg_img=anat_img, cmap='jet', symmetric_cmap=False, threshold=1e-6, colorbar=True, title='Mean beta for active voxels')\n",
    "# active_beta_view.save_as_html(file_name=f'active_beta_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78578f26",
   "metadata": {},
   "source": [
    "Apply Hampel Filter to have smooth beta value (remove voxels that have 0-2 neighbour, smooth beta for voxles with more than 2 neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hampel_filter_image(image, window_size, threshold_factor, return_stats=False):\n",
    "#     if window_size % 2 == 0:\n",
    "#         raise ValueError(\"window_size must be odd\")\n",
    "\n",
    "#     filtered = image.astype(float).copy()\n",
    "#     footprint = np.ones((window_size,) * 3, dtype=bool)\n",
    "\n",
    "#     insufficient_counts = []\n",
    "#     corrected_indices_parts = []\n",
    "\n",
    "#     for t in range(image.shape[3]):\n",
    "#         vol = image[..., t]\n",
    "#         med = ndimage.generic_filter(vol, np.nanmedian, footprint=footprint, mode='constant', cval=np.nan)\n",
    "#         mad = ndimage.generic_filter(np.abs(vol - med), np.nanmedian, footprint=footprint, mode='constant', cval=np.nan)\n",
    "#         counts = ndimage.generic_filter(np.isfinite(vol).astype(np.float32), np.sum, footprint=footprint, mode='constant', cval=0)\n",
    "\n",
    "#         scaled_mad = 1.4826 * mad\n",
    "#         insufficient = counts < 3\n",
    "#         insufficient_counts.append(int(np.count_nonzero(insufficient)))\n",
    "\n",
    "#         filtered[..., t][insufficient] = np.nan\n",
    "\n",
    "#         valid = np.isfinite(vol)\n",
    "#         enough_data = (~insufficient) & valid\n",
    "#         outliers = enough_data & (np.abs(vol - med) > threshold_factor * scaled_mad)\n",
    "\n",
    "#         if np.any(outliers):\n",
    "#             coords = np.argwhere(outliers)\n",
    "#             t_column = np.full((coords.shape[0], 1), t, dtype=int)\n",
    "#             corrected_indices_parts.append(np.hstack((coords, t_column)))\n",
    "\n",
    "#         filtered[..., t][outliers] = med[outliers]\n",
    "\n",
    "#     if return_stats:\n",
    "#         insufficient_counts_arr = np.array(insufficient_counts, dtype=int)\n",
    "#         if corrected_indices_parts:\n",
    "#             corrected_indices = np.vstack(corrected_indices_parts)\n",
    "#         else:\n",
    "#             corrected_indices = np.empty((0, 4), dtype=int)\n",
    "\n",
    "#         stats = {\n",
    "#             'insufficient_counts': insufficient_counts_arr,\n",
    "#             'insufficient_total': int(insufficient_counts_arr.sum()),\n",
    "#             'corrected_indices': corrected_indices,\n",
    "#             'corrected_total': int(corrected_indices.shape[0]),\n",
    "#         }\n",
    "#         return filtered, stats\n",
    "\n",
    "#     return filtered\n",
    "\n",
    "\n",
    "# beta_volume_filter, hampel_stats = hampel_filter_image(clean_active_volume, window_size=5, threshold_factor=3, return_stats=True)\n",
    "# print('Insufficient neighbours per frame:', hampel_stats['insufficient_counts'], flush=True)\n",
    "# print('Total voxels with <3 neighbours:', hampel_stats['insufficient_total'], flush=True)\n",
    "# print('Total corrected voxels:', hampel_stats['corrected_total'], flush=True)\n",
    "# if hampel_stats['corrected_total'] > 0:\n",
    "#     preview = hampel_stats['corrected_indices'][:5]\n",
    "#     print('Sample corrected voxel indices (x, y, z, t):', preview, flush=True)\n",
    "\n",
    "# # save cleaned beta volume\n",
    "# beta_volume_filter = beta_volume_filter[~np.all(np.isnan(beta_volume_filter), axis=-1)]\n",
    "# np.save(f'cleaned_beta_volume_sub{sub}_ses{ses}_run{run}.npy', beta_volume_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc62a09",
   "metadata": {},
   "source": [
    "Load the filtered beta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4764372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_valume_clean_2d = np.load(f'cleaned_beta_volume_sub{sub}_ses{ses}_run{run}.npy')\n",
    "print(beta_valume_clean_2d.shape)\n",
    "mask_2d = np.load(\"mask_all_nan_sub04_ses1_run1.npy\")\n",
    "np.sum(mask_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a587f52",
   "metadata": {},
   "source": [
    "plot beta hist again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = beta_valume_clean_2d.ravel()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.hist(tmp, density=True, bins=100)\n",
    "# ax.set_title('Cleaned beta')\n",
    "# ax.set_xlabel('beta')\n",
    "# ax.set_ylabel('density')\n",
    "# ax.set_xlim(np.nanmin(tmp), np.nanmax(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72890c1a",
   "metadata": {},
   "source": [
    "remove new voxels in the bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd58cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_flat_idx = np.ravel_multi_index(active_coords, clean_active_volume.shape[:3])\n",
    "active_keep_mask = ~mask_2d[active_flat_idx]\n",
    "clean_active_bold = clean_active_bold[active_keep_mask]\n",
    "clean_active_bold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert cleaned beta volume to a 2D array for optimization\n",
    "# beta_volume_filter = np.load('beta_valume_clean_2d.npy')\n",
    "# beta_volume_filter = beta_volume_filter.astype(np.float16)\n",
    "# spatial_shape = beta_volume_filter.shape[:-1]\n",
    "# voxels_with_any_nan = np.zeros(spatial_shape, dtype=bool)\n",
    "# voxels_with_all_nan = np.ones(spatial_shape, dtype=bool)\n",
    "\n",
    "# # Sweep the time dimension once\n",
    "# for t in range(beta_volume_filter.shape[-1]):\n",
    "#     frame_nan = np.isnan(beta_volume_filter[..., t])\n",
    "#     voxels_with_any_nan |= frame_nan\n",
    "#     voxels_with_all_nan &= frame_nan\n",
    "\n",
    "# print(np.sum(voxels_with_any_nan), np.sum(voxels_with_all_nan), flush=True)\n",
    "\n",
    "# n_trial = beta_volume_filter.shape[-1]\n",
    "# beta_volume_filter_2d = beta_volume_filter.reshape(-1, n_trial)\n",
    "# print(beta_volume_filter_2d.shape, flush=True)\n",
    "# mask_2d = voxels_with_all_nan.reshape(-1)\n",
    "# beta_valume_clean_2d = beta_volume_filter_2d[~mask_2d]\n",
    "# print(beta_valume_clean_2d.shape, flush=True)\n",
    "# np.save(f'beta_valume_clean_2d.npy', beta_valume_clean_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del anat_img, back_mask, csf_mask, white_mask, mask, nonzero_mask, masked_bold\n",
    "# del beta_run1, beta_run2, beta, clean_beta, voxels_with_all_nan, voxels_with_any_nan\n",
    "# del beta_volume_filter_2d, beta_valume_clean_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25ee58",
   "metadata": {},
   "source": [
    "Plot finall beta value on the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_2d = np.load(\"mask_all_nan_sub04_ses1_run1.npy\")\n",
    "# active_flat = np.ravel_multi_index(active_coords, clean_active_volume.shape[:3])\n",
    "# keep_mask = ~mask_2d[active_flat]                 # length = 315116 → 314734 True\n",
    "# filtered_coords = tuple(c[keep_mask] for c in active_coords)\n",
    "\n",
    "# beta_volume = np.full(bold_data.shape[:3] + (beta_valume_clean_2d.shape[1],), np.nan, np.float32)\n",
    "# beta_volume[filtered_coords[0], filtered_coords[1], filtered_coords[2], :] = beta_valume_clean_2d.astype(np.float32)\n",
    "# beta_map = np.nanmean(beta_volume, axis=3)\n",
    "# beta_img = nib.Nifti1Image(np.abs(beta_map), bold_img.affine, bold_img.header)\n",
    "# view = plotting.view_img(beta_img, bg_img=anat_img, threshold=0.0, cmap=\"jet\", symmetric_cmap=False)\n",
    "# view.save_as_html(file_name=f'final_beta.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd53b6",
   "metadata": {},
   "source": [
    "Load the clean beta, which is ready for optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_valume_clean_2d = np.load(f'beta_valume_clean_2d.npy')\n",
    "# beta_valume_clean_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652db5f",
   "metadata": {},
   "source": [
    "Create Matrices for Optim problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_matrices(\n",
    "#     beta_valume_clean_2d,\n",
    "#     bold_data,\n",
    "#     mask_2d,\n",
    "#     trial_indices=None,\n",
    "#     trial_len=9,\n",
    "#     num_components=600,\n",
    "#     pca_components=None,\n",
    "#     pca_mean=None):\n",
    "#     print(\"begin\", flush=True)\n",
    "#     print(type(mask_2d))\n",
    "#     num_trials = beta_valume_clean_2d.shape[-1]\n",
    "#     trial_idx = np.arange(num_trials) if trial_indices is None else np.unique(np.asarray(trial_indices, int).ravel())\n",
    "\n",
    "#     # ----- reshape BOLD into trials -----\n",
    "#     bold_data_reshape = bold_data.reshape(-1, bold_data.shape[-1])\n",
    "#     print(bold_data.reshape(-1, bold_data.shape[-1]).shape[0], mask_2d.dtype, mask_2d.size)\n",
    "#     bold_data_selected = bold_data_reshape[~mask_2d]         # keep voxels of interest\n",
    "#     bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len), dtype=np.float32)\n",
    "#     start = 0\n",
    "    \n",
    "#     for i in range(num_trials):\n",
    "#         end = start + trial_len\n",
    "#         if end > bold_data_selected.shape[1]:\n",
    "#             raise ValueError(\"BOLD data does not contain enough timepoints for all trials\")\n",
    "#         bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:end]\n",
    "#         start += trial_len\n",
    "#         if start == 270 or start == 560:   # your skips\n",
    "#             start += 20\n",
    "#     X = bold_data_selected_reshape[:, trial_idx, :]          # [Nvox, Ntrials, T]\n",
    "#     print(\"BOLD reshaped before PCA\", X.shape, flush=True)\n",
    "\n",
    "#     # ----- apply PCA -----\n",
    "#     print(\"PCA...\", flush=True)\n",
    "#     X_reshap = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "\n",
    "#     if pca_components is None or pca_mean is None:\n",
    "#         pca = PCA()\n",
    "#         X_pca_full = pca.fit_transform(X_reshap.T).astype(np.float32)\n",
    "#         components = pca.components_.astype(np.float32)\n",
    "#         mean = pca.mean_.astype(np.float32)\n",
    "#         n_components = min(num_components, components.shape[0])\n",
    "#         components = components[:n_components]\n",
    "#         X_pca = X_pca_full[:, :n_components]\n",
    "#     else:\n",
    "#         components = pca_components.astype(np.float32)\n",
    "#         mean = pca_mean.astype(np.float32)\n",
    "#         n_components = components.shape[0]\n",
    "#         X_centered = X_reshap.T - mean\n",
    "#         X_pca = (X_centered @ components.T).astype(np.float32)\n",
    "\n",
    "#     beta_reduced = (beta_valume_clean_2d.T - mean) @ components.T\n",
    "#     beta_reduced = beta_reduced.T\n",
    "\n",
    "\n",
    "#     # ----- L_task (same idea as yours) -----\n",
    "#     print(\"L_task...\", flush=True)\n",
    "#     beta_selected = beta_reduced[:, trial_idx]\n",
    "#     counts = np.count_nonzero(np.isfinite(beta_selected), axis=-1)\n",
    "#     sums = np.nansum(beta_selected, axis=-1, dtype=np.float64)\n",
    "#     mean_beta = np.zeros(beta_selected.shape[0], dtype=np.float32)\n",
    "#     m = counts > 0\n",
    "#     mean_beta[m] = np.abs((sums[m] / counts[m])).astype(np.float32)\n",
    "#     L_task = np.zeros_like(mean_beta, dtype=np.float32)\n",
    "#     v = np.abs(mean_beta) > 0\n",
    "#     L_task[v] = (1.0 / mean_beta[v]).astype(np.float32)\n",
    "\n",
    "#     # ----- L_var_bold: variance of trial differences, as sparse diagonal -----\n",
    "#     print(\"L_var...\", flush=True)\n",
    "#     X_pca = X_pca[:, :n_components].T\n",
    "#     num_trials = len(trial_idx)\n",
    "#     X = X_pca.reshape(X_pca.shape[0], num_trials, trial_len)\n",
    "#     L_var_bold = np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)\n",
    "#     for i in range(num_trials-1):\n",
    "#         x1 = X[:, i, :]\n",
    "#         x2 = X[:, i+1, :]\n",
    "#         L_var_bold += (x1-x2) @ (x1-x2).T\n",
    "#     L_var_bold /= (num_trials - 1)\n",
    "\n",
    "#     # ----- L_var_beta: variance of trial differences, as sparse diagonal -----\n",
    "#     print(\"L_var...\", flush=True)\n",
    "#     num_trials = len(trial_idx)\n",
    "#     X = beta_reduced\n",
    "#     L_var_beta = np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)\n",
    "#     for i in range(num_trials-1):\n",
    "#         x1 = X[:, i]\n",
    "#         x2 = X[:, i+1]\n",
    "#         L_var_bold += (x1-x2) @ (x1-x2).T\n",
    "#     L_var_beta /= (num_trials - 1)\n",
    "\n",
    "#     selected_BOLD_flat = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "#     return L_task.astype(np.float32), L_var, L_var_beta, selected_BOLD_flat, components, mean\n",
    "\n",
    "# # %%\n",
    "# def objective_func(w, L_task, L_var_bold, L_var_beta, alpha_var_bold, alpha_var_beta):\n",
    "#     print(\"Calculating objective...\", flush=True)\n",
    "#     L_task = zscore(L_task)\n",
    "#     L_var_bold = zscore(L_var_bold)\n",
    "#     L_var_beta = zscore(L_var_beta)\n",
    "#     quad = (w.T @ np.diag(L_task) @ w + alpha_var_bold * (w.T @ L_var_bold @ w) + alpha_var_beta * (w.T @ L_var_beta @ w))\n",
    "#     return quad\n",
    "\n",
    "# # %%\n",
    "# def optimize_voxel_weights(L_task, L_var, alpha_var):\n",
    "#     print(\"Optimizing voxel weights...\", flush=True)\n",
    "#     L_total = np.diag(L_task) + alpha_var * L_var\n",
    "#     n = L_total.shape[0]\n",
    "#     L_total = np.nan_to_num(L_total)\n",
    "#     L_total = 0.5*(L_total + L_total.T) + 1e-6*np.eye(n)\n",
    "#     eigvals, eigvecs = np.linalg.eigh(L_total)\n",
    "#     eigvals[eigvals < 0] = 0.0  # clip the numerical negatives\n",
    "#     L_total_psd = (eigvecs @ np.diag(eigvals) @ eigvecs.T).astype(np.float64)\n",
    "\n",
    "#     w = cp.Variable(n, nonneg=True)\n",
    "#     constraints = [cp.sum(w) == 1]\n",
    "\n",
    "#     objective = cp.Minimize(cp.quad_form(w, cp.psd_wrap(L_total_psd)))\n",
    "#     problem = cp.Problem(objective, constraints)\n",
    "#     problem.solve(solver=cp.OSQP, verbose=True)\n",
    "#     return w.value\n",
    "\n",
    "\n",
    "# # %%\n",
    "# def calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len):\n",
    "#     kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#     best_score = np.inf\n",
    "#     best_alpha_var = None\n",
    "#     num_trials = beta_valume_clean_2d.shape[-1]\n",
    "\n",
    "#     for a_var_bold in param_grid[\"alpha_var\"]:\n",
    "#         fold_scores = []\n",
    "#         print(f\"a_var: {a_var_bold}\", flush=True)\n",
    "#         count = 1\n",
    "\n",
    "#         for train_idx, val_idx in kf.split(np.arange(num_trials)):\n",
    "#             print(f\"k-fold num: {count}\", flush=True)\n",
    "#             print(type(mask_2d), flush=True)\n",
    "#             L_task_train, L_var_bold_train, L_var_beta_train, _, pca_components, pca_mean = calculate_matrices(\n",
    "#                 beta_valume_clean_2d,\n",
    "#                 bold_data,\n",
    "#                 mask_2d,\n",
    "#                 train_idx,\n",
    "#                 trial_len,\n",
    "#             )\n",
    "#             w = optimize_voxel_weights(L_task_train, L_var_train, alpha_var=a_var_bold)\n",
    "\n",
    "#             L_task_val, L_var_bold_val, L_var_beta_val, _, _, _ = calculate_matrices(\n",
    "#                 beta_valume_clean_2d,\n",
    "#                 bold_data,\n",
    "#                 mask_2d,\n",
    "#                 val_idx,\n",
    "#                 trial_len,\n",
    "#                 pca_components=pca_components,\n",
    "#                 pca_mean=pca_mean,\n",
    "#             )\n",
    "\n",
    "#             fold_scores.append(objective_func(w, L_task_val, L_var_bold_val, L_var_beta_val, a_var_bold, alpha_var_beta))\n",
    "#             print(f\"fold_scores: {fold_scores}\", flush=True)\n",
    "#             count += 1\n",
    "\n",
    "#         mean_score = np.mean(fold_scores)\n",
    "#         print(mean_score)\n",
    "#         if mean_score < best_score:\n",
    "#             best_score = mean_score\n",
    "#             best_alpha_var = a_var_bold\n",
    "\n",
    "#     print(\"Best alpha_var:\", best_alpha_var, \"with CV loss:\", best_score, flush=True)\n",
    "#     return best_alpha_var, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48811eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, trial_indices=None, trial_len=9, num_components=600, pca_components=None, pca_mean=None):\n",
    "    print(\"begin\", flush=True)\n",
    "    print(type(mask_2d))\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "    trial_idx = np.arange(num_trials) if trial_indices is None else np.unique(np.asarray(trial_indices, int).ravel())\n",
    "\n",
    "    # ----- reshape BOLD into trials -----\n",
    "    bold_data_reshape = bold_data.reshape(-1, bold_data.shape[-1])\n",
    "    print(bold_data.reshape(-1, bold_data.shape[-1]).shape[0], mask_2d.dtype, mask_2d.size)\n",
    "    bold_data_selected = bold_data_reshape[~mask_2d]         # keep voxels of interest\n",
    "    bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len), dtype=np.float32)\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        end = start + trial_len\n",
    "        if end > bold_data_selected.shape[1]:\n",
    "            raise ValueError(\"BOLD data does not contain enough timepoints for all trials\")\n",
    "        bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:end]\n",
    "        start += trial_len\n",
    "        if start == 270 or start == 560:   # your skips\n",
    "            start += 20\n",
    "    X = bold_data_selected_reshape[:, trial_idx, :]          # [Nvox, Ntrials, T]\n",
    "    print(\"BOLD reshaped before PCA\", X.shape, flush=True)\n",
    "\n",
    "    # ----- apply PCA -----\n",
    "    print(\"PCA...\", flush=True)\n",
    "    X_reshap = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "\n",
    "    if pca_components is None or pca_mean is None:\n",
    "        print(1)\n",
    "        pca = PCA()\n",
    "        X_pca_full = pca.fit_transform(X_reshap.T).astype(np.float32)\n",
    "        components = pca.components_.astype(np.float32)\n",
    "        mean = pca.mean_.astype(np.float32)\n",
    "        n_components = min(num_components, components.shape[0])\n",
    "        components = components[:n_components]\n",
    "        X_pca = X_pca_full[:, :n_components]\n",
    "    else:\n",
    "        print(2)\n",
    "        components = pca_components.astype(np.float32)\n",
    "        mean = pca_mean.astype(np.float32)\n",
    "        n_components = components.shape[0]\n",
    "        X_centered = X_reshap.T - mean\n",
    "        X_pca = (X_centered @ components.T).astype(np.float32)\n",
    "\n",
    "    print(beta_valume_clean_2d.shape)\n",
    "    print(components.shape)\n",
    "    beta_reduced = (beta_valume_clean_2d.T - mean) @ components.T\n",
    "    beta_reduced = beta_reduced.T\n",
    "\n",
    "\n",
    "    # ----- L_task (same idea as yours) -----\n",
    "    print(\"L_task...\", flush=True)\n",
    "    beta_selected = beta_reduced[:, trial_idx]\n",
    "    counts = np.count_nonzero(np.isfinite(beta_selected), axis=-1)\n",
    "    sums = np.nansum(np.abs(beta_selected), axis=-1, dtype=np.float64)\n",
    "    mean_beta = np.zeros(beta_selected.shape[0], dtype=np.float32)\n",
    "    m = counts > 0\n",
    "    mean_beta[m] = (sums[m] / counts[m]).astype(np.float32)\n",
    "    L_task = np.zeros_like(mean_beta, dtype=np.float32)\n",
    "    v = np.abs(mean_beta) > 0\n",
    "    L_task[v] = (1.0 / mean_beta[v]).astype(np.float32)\n",
    "\n",
    "    # ----- L_var_bold: variance of trial differences, as sparse diagonal -----\n",
    "    print(\"L_var...\", flush=True)\n",
    "    X_pca = X_pca[:, :n_components].T\n",
    "    num_trials = len(trial_idx)\n",
    "    X = X_pca.reshape(X_pca.shape[0], num_trials, trial_len)\n",
    "    L_var_bold = np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)\n",
    "    for i in range(num_trials-1):\n",
    "        x1 = X[:, i, :]\n",
    "        x2 = X[:, i+1, :]\n",
    "        L_var_bold += (x1-x2) @ (x1-x2).T\n",
    "    L_var_bold /= (num_trials - 1)\n",
    "\n",
    "    # ----- L_var_beta: variance of trial differences, as sparse diagonal -----\n",
    "    print(\"L_var...\", flush=True)\n",
    "    num_trials = len(trial_idx)\n",
    "    X = beta_reduced\n",
    "    L_var_beta = np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)\n",
    "    for i in range(num_trials-1):\n",
    "        x1 = X[:, i]\n",
    "        x2 = X[:, i+1]\n",
    "        L_var_bold += (x1-x2) @ (x1-x2).T\n",
    "    L_var_beta /= (num_trials - 1)\n",
    "\n",
    "    selected_BOLD_flat = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "    return L_task.astype(np.float32), L_var_beta, L_var_beta, selected_BOLD_flat, components, mean\n",
    "\n",
    "# %%\n",
    "def objective_func(w, L_task, L_var_bold, L_var_beta, alpha_var_bold, alpha_var_beta):\n",
    "    print(\"Calculating objective...\", flush=True)\n",
    "    def _safe_scale(arr):\n",
    "        scale = np.max(np.abs(arr))\n",
    "        if not np.isfinite(scale) or scale <= 0:\n",
    "            scale = 1.0\n",
    "        print(f\"scale: {scale}\")\n",
    "        return arr / scale\n",
    "\n",
    "    L_task_scaled = _safe_scale(L_task)\n",
    "    L_var_bold_scaled = _safe_scale(L_var_bold)\n",
    "    L_var_beta_scaled = _safe_scale(L_var_beta)\n",
    "\n",
    "    quad = (w.T @ np.diag(L_task_scaled) @ w + alpha_var_bold * (w.T @ L_var_bold_scaled @ w) + \n",
    "            alpha_var_beta * (w.T @ L_var_beta_scaled @ w))\n",
    "    return quad\n",
    "\n",
    "# %%\n",
    "def optimize_voxel_weights(L_task, L_var_bold, L_var_beta, alpha_var_bold, alpha_var_beta):\n",
    "    print(\"Optimizing voxel weights...\", flush=True)\n",
    "    def _safe_scale(arr):\n",
    "        scale = np.max(np.abs(arr))\n",
    "        print(scale)\n",
    "        if not np.isfinite(scale) or scale <= 0:\n",
    "            scale = 1.0\n",
    "        print(f\"scale: {scale}\")\n",
    "        return arr / scale\n",
    "\n",
    "    L_task_scaled = _safe_scale(L_task)\n",
    "    L_var_bold_scaled = _safe_scale(L_var_bold)\n",
    "    L_var_beta_scaled = _safe_scale(L_var_beta)\n",
    "\n",
    "    L_total = (np.diag(L_task_scaled) + alpha_var_bold * L_var_bold_scaled + alpha_var_beta * L_var_beta_scaled)\n",
    "    L_total = np.nan_to_num(L_total, copy=False).astype(np.float64, copy=False)\n",
    "    L_total = 0.5 * (L_total + L_total.T)\n",
    "    L_total += 1e-8 * np.eye(L_total.shape[0])\n",
    "\n",
    "    w = cp.Variable(L_total.shape[0], nonneg=True)\n",
    "    constraints = [cp.sum(w) == 1]\n",
    "\n",
    "    objective = cp.Minimize(cp.quad_form(w, cp.psd_wrap(L_total)))\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.OSQP, verbose=True)\n",
    "    return w.value\n",
    "\n",
    "\n",
    "# %%\n",
    "def calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len):\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    best_score = np.inf\n",
    "    best_alpha_var_bold = None\n",
    "    best_alpha_var_beta = None\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "\n",
    "    for alpha_var_bold, alpha_var_beta in product(param_grid[\"alpha_var_bold\"], param_grid[\"alpha_var_beta\"]):\n",
    "        fold_scores = []\n",
    "        print(f\"a_var: {alpha_var_bold}, {alpha_var_beta}\", flush=True)\n",
    "        count = 1\n",
    "\n",
    "        for train_idx, val_idx in kf.split(np.arange(num_trials)):\n",
    "            print(f\"k-fold num: {count}\", flush=True)\n",
    "            # print(type(mask_2d), flush=True)\n",
    "            # print(f\"11: {beta_valume_clean_2d.shape}\")\n",
    "            L_task_train, L_var_bold_train, L_var_beta_train, _, pca_components, pca_mean = calculate_matrices(\n",
    "                beta_valume_clean_2d, bold_data, mask_2d, train_idx, trial_len)\n",
    "            w = optimize_voxel_weights(L_task_train, L_var_bold_train, L_var_beta_train, alpha_var_bold, alpha_var_beta)\n",
    "\n",
    "            L_task_val, L_var_bold_val, L_var_beta_val, _, _, _ = calculate_matrices(beta_valume_clean_2d, bold_data, \n",
    "            mask_2d, val_idx, trial_len, pca_components=pca_components, pca_mean=pca_mean)\n",
    "\n",
    "            fold_scores.append(objective_func(w, L_task_val, L_var_bold_val, L_var_beta_val, alpha_var_bold, alpha_var_beta))\n",
    "            print(f\"fold_scores: {fold_scores}\", flush=True)\n",
    "            count += 1\n",
    "\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        print(mean_score)\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_alpha_var_bold = alpha_var_bold\n",
    "            best_alpha_var_beta = alpha_var_beta\n",
    "\n",
    "    print(\"Best alpha_var_bold:\", best_alpha_var_bold, \"Best alpha_var_beta:\", best_alpha_var_beta, \"with CV loss:\", best_score, flush=True)\n",
    "    return alpha_var_bold, alpha_var_beta, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f390527",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha_var_bold\": [0.01],\n",
    "              \"alpha_var_beta\": [0.01]}\n",
    "\n",
    "trial_len = 9\n",
    "# beta_valume_clean_2d = clean_active_beta\n",
    "best_alpha_var_bold, best_alpha_var_beta, best_score = calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len)\n",
    "# L_task, L_var_bold, L_var_beta, selected_BOLD_flat, pca_components, pca_mean = calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, None, trial_len)\n",
    "# print(f\"best alpha_var: {best_alpha_var_bold}, {best_alpha_var_beta}, best_score: {best_score}\", flush=True)\n",
    "# weights = optimize_voxel_weights(L_task, L_task, L_var_bold, L_var_beta, best_alpha_var_bold, best_alpha_var_beta)\n",
    "# voxel_space_weights = pca_components.T @ weights\n",
    "# y = selected_BOLD_flat.T @ weights\n",
    "\n",
    "# np.save('weights.npy', weights)\n",
    "# np.save('voxel_space_weights.npy', voxel_space_weights)\n",
    "# np.save('pca_components.npy', pca_components)\n",
    "# np.save('pca_mean.npy', pca_mean)\n",
    "# np.save('y.npy', y)\n",
    "# print(\"Finished!\", flush=True)\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745b0aa",
   "metadata": {},
   "source": [
    "Analysis the Optim Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbbf1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effc4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2 = 0.1, 0.1\n",
    "L_task = np.load('results/L_task.npy') # (588,)\n",
    "L_var_beta = np.load('results/L_var_beta.npy') # (588,588)\n",
    "L_var_bold = np.load('results/L_var_bold.npy') # (588,588)\n",
    "# voxel_space_weights = np.load(f'results/{s1}_{s2}_voxel_space_weights.npy') #(314734,)\n",
    "# # weights = np.load(f'results/{s1}_{s2}_weights.npy') # (588,)\n",
    "# y = np.load(f'results/{s1}_{s2}_y.npy') #(810)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb678c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Task loss line plot ---\n",
    "fig_task, ax_task = plt.subplots(figsize=(6, 4))\n",
    "sns.lineplot(x=np.arange(L_task.shape[0]), y=L_task / np.max(L_task), ax=ax_task, color=\"steelblue\")\n",
    "ax_task.set(xlabel=\"Index\", ylabel=\"L_task\", title=\"Task Loss\")\n",
    "fig_task.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- L_var_beta heatmap ---\n",
    "from matplotlib import colors\n",
    "\n",
    "tmp = L_var_beta / np.max(L_var_beta)\n",
    "mask = np.isclose(tmp, 1.0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "ranges = [(0, 100), (100, 300), (300, 600)]\n",
    "\n",
    "for ax, (start, end) in zip(axes, ranges):\n",
    "    data = tmp[start:end, start:end]\n",
    "    data_mask = mask[start:end, start:end]\n",
    "    sns.heatmap(data, mask=data_mask, ax=ax, cmap=\"jet\", cbar=ax)\n",
    "    ax.set(xlabel=\"component\", ylabel=\"component\", title=f\"L_var_beta ({start}–{end})\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    tick_idx = np.linspace(0, data.shape[0] - 1, 5, dtype=int)\n",
    "    tick_labels = np.linspace(start, end, 5, dtype=int)\n",
    "    ax.set_xticks(tick_idx)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(tick_idx)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# --- L_var_bold heatmap ---\n",
    "tmp = L_var_bold / np.max(L_var_bold)\n",
    "mask = np.isclose(tmp, 1.0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "ranges = [(0, 100), (100, 300), (300, 600)]\n",
    "\n",
    "for ax, (start, end) in zip(axes, ranges):\n",
    "    data = tmp[start:end, start:end]\n",
    "    data_mask = mask[start:end, start:end]\n",
    "    sns.heatmap(data, mask=data_mask, ax=ax, cmap=\"jet\", cbar=ax)\n",
    "    ax.set(xlabel=\"component\", ylabel=\"component\", title=f\"L_var_bold ({start}–{end})\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    tick_idx = np.linspace(0, data.shape[0] - 1, 5, dtype=int)\n",
    "    tick_labels = np.linspace(start, end, 5, dtype=int)\n",
    "    ax.set_xticks(tick_idx)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(tick_idx)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ff633",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hist, hist_axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "sns.histplot(L_task/np.max(L_task), bins=30, ax=hist_axes[0], color=\"steelblue\")\n",
    "hist_axes[0].set(xlabel=\"L_task\", ylabel=\"Count\", title=\"L_task Distribution\")\n",
    "hist_axes[0].set_yscale(\"log\")\n",
    "\n",
    "sns.histplot(L_var_beta.ravel()/np.max(L_var_beta), bins=30, ax=hist_axes[1], color=\"seagreen\")\n",
    "hist_axes[1].set(xlabel=\"Value\", ylabel=\"Count\", title=\"L_var_beta Distribution\")\n",
    "hist_axes[1].set_yscale(\"log\")\n",
    "\n",
    "sns.histplot(L_var_bold.ravel()/np.max(L_var_bold), bins=30, ax=hist_axes[2], color=\"darkmagenta\")\n",
    "hist_axes[2].set(xlabel=\"Value\", ylabel=\"Count\", title=\"L_var_bold Distribution\")\n",
    "hist_axes[2].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a45dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2 = 0.05, 10\n",
    "voxel_space_weights = np.load(f'results/{s1}_{s2}_voxel_space_weights.npy') #(314734,)\n",
    "weights = np.load(f'results/{s1}_{s2}_weights.npy') # (588,)\n",
    "y = np.load(f'results/{s1}_{s2}_y.npy') #(810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hist, hist_axes = plt.subplots(1, 2, figsize=(18, 4))\n",
    "\n",
    "sns.histplot(voxel_space_weights, bins=30, ax=hist_axes[0], color=\"steelblue\")\n",
    "hist_axes[0].set(xlabel=\"voxels weights\", ylabel=\"Count(log)\", title=\"voxels weights Distribution\")\n",
    "hist_axes[0].set_yscale(\"log\")\n",
    "\n",
    "sns.histplot(weights, bins=30, ax=hist_axes[1], color=\"steelblue\")\n",
    "hist_axes[1].set(xlabel=\"comp weights\", ylabel=\"Count\", title=\"components weights Distribution\")\n",
    "# hist_axes[1].set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y)\n",
    "plt.xlabel(\"time\")\n",
    "plt.title(\"reconstructed Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0358c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_vol = np.zeros(bold_data.shape[:3], dtype=np.float32)\n",
    "active_coords_kept = tuple(coord[active_keep_mask] for coord in active_coords)\n",
    "weight_vol[active_coords_kept] = np.abs(voxel_space_weights)\n",
    "\n",
    "weight_img = nib.Nifti1Image(weight_vol, bold_img.affine)\n",
    "weight_img_resamp = resample_to_img(weight_img, anat_img, interpolation=\"continuous\")\n",
    "\n",
    "view = plotting.view_img(\n",
    "    weight_img_resamp,\n",
    "    bg_img=anat_img,\n",
    "    threshold=np.percentile(voxel_space_weights, 95),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"jet\",\n",
    "    draw_cross=False,\n",
    "    colorbar=True,\n",
    ")\n",
    "view.save_as_html(file_name=f'weights_map_{s1}_{s2}_thrshold_95.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a008e3",
   "metadata": {},
   "source": [
    "Corr between Y & Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64f61ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/Behaviour/PSPD004/PSPD004_OFF_Run_1.mat\"\n",
    "import h5py\n",
    "with h5py.File(path, 'r') as f:\n",
    "    behav_data = {key: np.array(f[key]) for key in f.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2ed68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_time = behav_data['squeeze_during_go_x_matrix'] #squeeze_time.shape\n",
    "squeeze_time = np.reshape(squeeze_time, (90, squeeze_time.shape[-1]))\n",
    "squeeze_time_var = np.var(squeeze_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f603c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reshaped = np.reshape(y, (90, 9))\n",
    "y_reshaped_var = np.var(y_reshaped, axis=1)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "r, p = pearsonr(y_reshaped_var, squeeze_time_var)\n",
    "print(f\"Pearson correlation: r={r}, p-value={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878757e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ac010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
