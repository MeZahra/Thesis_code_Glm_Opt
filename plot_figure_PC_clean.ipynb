{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77b5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from nilearn import plotting\n",
    "from nilearn.image import resample_to_img\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.sparse import csgraph\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deddd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = 1\n",
    "sub = '04'\n",
    "run = 1\n",
    "\n",
    "base_path = '/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives'\n",
    "anat_img = nib.load(f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain.nii.gz')\n",
    "\n",
    "data_name = f'sub-pd0{sub}_ses-{ses}_run-{run}_task-mv_bold_corrected_smoothed_reg.nii.gz'\n",
    "BOLD_path_org = join(base_path, f'sub-pd0{sub}', f'ses-{ses}', 'func', data_name)\n",
    "bold_img = nib.load(BOLD_path_org)\n",
    "bold_data = bold_img.get_fdata()\n",
    "bold_data = bold_data.astype(np.float16)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_mask.nii.gz'\n",
    "back_mask = nib.load(mask_path)\n",
    "back_mask = back_mask.get_fdata()\n",
    "back_mask = back_mask.astype(np.float16)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_0.nii.gz'\n",
    "csf_mask = nib.load(mask_path)\n",
    "csf_mask = csf_mask.get_fdata()\n",
    "csf_mask = csf_mask.astype(np.float16)\n",
    "\n",
    "mask_path = f'/mnt/TeamShare/Data_Masterfile/H20-00572_All-Dressed/PRECISIONSTIM_PD_Data_Results/fMRI_preprocessed_data/Rev_pipeline/derivatives/sub-pd0{sub}/ses-{ses}/anat/sub-pd0{sub}_ses-{ses}_T1w_brain_pve_1.nii.gz'\n",
    "white_mask = nib.load(mask_path)\n",
    "white_mask = white_mask.get_fdata()\n",
    "white_mask = white_mask.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc899be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected voxels after masking: 7.91%\n",
      "bold_data masked shape: (619385, 850)\n"
     ]
    }
   ],
   "source": [
    "back_mask_data = back_mask > 0\n",
    "csf_mask_data = csf_mask > 0\n",
    "white_mask_data = white_mask > 0.5\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "mask &= ~white_mask_data\n",
    "nonzero_mask = np.where(mask)\n",
    "masked_bold = bold_data[nonzero_mask]\n",
    "\n",
    "print(f\"number of selected voxels after masking: {masked_bold.shape[0]/math.prod(bold_data.shape[:3])*100:.2f}%\")\n",
    "print('bold_data masked shape:', masked_bold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d6e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Range:[ -1854.696 19687.86 ], Mean:  0.00972046\n",
      "low_thr: -4.41, high_thr: 4.42\n",
      "percentage of voxels with extreme beta values: 7.53%\n"
     ]
    }
   ],
   "source": [
    "glm_dict = np.load(f'TYPED_FITHRF_GLMDENOISE_RR.npy', allow_pickle=True).item()\n",
    "beta_glm = glm_dict['betasmd']\n",
    "beta_run1, beta_run2 = beta_glm[:,0,0,:90], beta_glm[:,0,0,90:]\n",
    "R2_run1, R2_run2 = glm_dict['R2run'][:,:,:,0], glm_dict['R2run'][:,:,:,1]\n",
    "\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "nonzero_mask = np.where(mask)\n",
    "white_mask_flat = white_mask_data[nonzero_mask]\n",
    "beta = beta_run1[~white_mask_flat]\n",
    "print(\"Beta Range:[\", np.nanmin(beta), np.nanmax(beta), \"], Mean: \", np.nanmean(beta))\n",
    "\n",
    "lower_thr, upper_thr = np.nanpercentile(beta, [1, 99])\n",
    "print(f'low_thr: {lower_thr:.2f}, high_thr: {upper_thr:.2f}') #low_thr: -4.64, high_thr: 4.60\n",
    "beta_extreme_mask = np.logical_or(beta < lower_thr, beta > upper_thr)\n",
    "voxels_with_extreme_beta = np.any(beta_extreme_mask, axis=1)\n",
    "\n",
    "print(f\"percentage of voxels with extreme beta values: {np.sum(voxels_with_extreme_beta)/beta.shape[0]*100:.2f}%\")\n",
    "\n",
    "mask = np.logical_and(back_mask_data, ~csf_mask_data)\n",
    "mask &= ~white_mask_data\n",
    "nonzero_mask = np.where(mask)\n",
    "\n",
    "# after removing voxels with extreme beta values\n",
    "clean_beta = beta[~voxels_with_extreme_beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "829d18ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 256, 170, 90)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_volume_filter = np.load(\"beta_volume_filter.npy\")\n",
    "beta_volume_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9165060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296838, 90)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_volume_filter = beta_volume_filter.astype(np.float16)\n",
    "spatial_shape = beta_volume_filter.shape[:-1]\n",
    "voxels_with_any_nan = np.zeros(spatial_shape, dtype=bool)\n",
    "voxels_with_all_nan = np.ones(spatial_shape, dtype=bool)\n",
    "\n",
    "# Sweep the time dimension once\n",
    "for t in range(beta_volume_filter.shape[-1]):\n",
    "    frame_nan = np.isnan(beta_volume_filter[..., t])\n",
    "    voxels_with_any_nan |= frame_nan\n",
    "    voxels_with_all_nan &= frame_nan\n",
    "\n",
    "n_trial = beta_volume_filter.shape[-1]\n",
    "beta_volume_filter_2d = beta_volume_filter.reshape(-1, n_trial)\n",
    "\n",
    "mask_2d = voxels_with_all_nan.reshape(-1)\n",
    "beta_valume_clean_2d = beta_volume_filter_2d[~mask_2d]\n",
    "\n",
    "beta_valume_clean_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce552248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, trial_indices=None, trial_len=9, num_components=600):\n",
    "    print(\"begin\")\n",
    "    print(type(mask_2d))\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "    trial_idx = np.arange(num_trials) if trial_indices is None else np.unique(np.asarray(trial_indices, int).ravel())\n",
    "\n",
    "    # ----- reshape BOLD into trials -----\n",
    "    bold_data_reshape = bold_data.reshape(-1, bold_data.shape[-1])\n",
    "    print(bold_data.reshape(-1, bold_data.shape[-1]).shape[0], mask_2d.dtype, mask_2d.size)\n",
    "    bold_data_selected = bold_data_reshape[~mask_2d]         # keep voxels of interest\n",
    "    bold_data_selected_reshape = np.zeros((bold_data_selected.shape[0], num_trials, trial_len), dtype=np.float32)\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        end = start + trial_len\n",
    "        if end > bold_data_selected.shape[1]:\n",
    "            raise ValueError(\"BOLD data does not contain enough timepoints for all trials\")\n",
    "        bold_data_selected_reshape[:, i, :] = bold_data_selected[:, start:end]\n",
    "        start += trial_len\n",
    "        if start == 270 or start == 560:   # your skips\n",
    "            start += 20\n",
    "    X = bold_data_selected_reshape[:, trial_idx, :]          # [Nvox, Ntrials, T]\n",
    "\n",
    "    # ----- apply PCA -----\n",
    "    print(\"PCA...\")\n",
    "    pca = PCA()\n",
    "    X_reshap = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "    X_pca = pca.fit_transform(X_reshap.T) #(810, 800)\n",
    "\n",
    "    components = pca.components_[:num_components]\n",
    "    mean = pca.mean_\n",
    "    beta_reduced = (beta_valume_clean_2d.T - mean) @ components.T\n",
    "    beta_reduced = beta_reduced.T\n",
    "\n",
    "\n",
    "    # ----- L_task (same idea as yours) -----\n",
    "    print(\"L_task...\")\n",
    "    beta_selected = beta_reduced[:, trial_idx]\n",
    "    counts = np.count_nonzero(np.isfinite(beta_selected), axis=-1)\n",
    "    sums = np.nansum(beta_selected, axis=-1, dtype=np.float64)\n",
    "    mean_beta = np.zeros(beta_selected.shape[0], dtype=np.float32)\n",
    "    m = counts > 0\n",
    "    mean_beta[m] = (sums[m] / counts[m]).astype(np.float32)\n",
    "    L_task = np.zeros_like(mean_beta, dtype=np.float32)\n",
    "    v = np.abs(mean_beta) > 0\n",
    "    L_task[v] = (1.0 / np.abs(mean_beta[v])).astype(np.float32)\n",
    "\n",
    "\n",
    "    # ----- L_var: variance of trial differences, as sparse diagonal -----\n",
    "    print(\"L_var...\")\n",
    "    X_pca = X_pca[:, :600].T\n",
    "    num_trials = len(trial_idx)\n",
    "    X = X_pca.reshape(X_pca.shape[0], num_trials, trial_len)\n",
    "    L_var = np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)\n",
    "    for i in range(num_trials-1):\n",
    "        x1 = X[:, i, :]\n",
    "        x2 = X[:, i+1, :]\n",
    "        L_var += (x1-x2) @ (x1-x2).T\n",
    "    L_var /= (num_trials - 1)\n",
    "\n",
    "    # selected_BOLD_flat = X.reshape(X.shape[0], -1).astype(np.float32)\n",
    "    return L_task.astype(np.float32), L_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785d02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(w, L_task, L_var, alpha_var):\n",
    "    print(\"Calculating objective...\")\n",
    "    quad = (w.T @ np.diag(L_task) @ w + alpha_var * (w.T @ L_var @ w))\n",
    "    return quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f47abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_voxel_weights(L_task, L_var, alpha_var):\n",
    "    print(\"Optimizing voxel weights...\")\n",
    "    L_total = np.diag(L_task) + alpha_var * L_var\n",
    "    n = L_total.shape[0]\n",
    "    L_total = np.nan_to_num(L_total)\n",
    "    L_total = 0.5*(L_total + L_total.T) + 1e-6*np.eye(n)\n",
    "    eigvals, eigvecs = np.linalg.eigh(L_total)\n",
    "    eigvals[eigvals < 0] = 0.0  # clip the numerical negatives\n",
    "    L_total_psd = (eigvecs @ np.diag(eigvals) @ eigvecs.T).astype(np.float64)\n",
    "\n",
    "    w = cp.Variable(n, nonneg=True)\n",
    "    constraints = [cp.sum(w) == 1]\n",
    "\n",
    "    # objective = cp.Minimize(cp.quad_form(w, L_total) + alpha_sparse * cp.norm1(w))\n",
    "    # objective = cp.Minimize(cp.quad_form(w, L_total))\n",
    "    objective = cp.Minimize(cp.quad_form(w, cp.psd_wrap(L_total_psd)))\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.OSQP, verbose=True)\n",
    "    return w.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029ee7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len):\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=0)\n",
    "    best_score = np.inf\n",
    "    best_params = None\n",
    "    num_trials = beta_valume_clean_2d.shape[-1]\n",
    "\n",
    "    for a_var in param_grid[\"alpha_var\"]:\n",
    "        fold_scores = []\n",
    "        print(f\"a_var: {a_var}\")\n",
    "        count = 1\n",
    "\n",
    "        for train_idx, val_idx in kf.split(np.arange(num_trials)):\n",
    "            print(f\"k-fold num: {count}\")\n",
    "            print(type(mask_2d))\n",
    "            L_task_train, L_var_train = calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, train_idx, trial_len)\n",
    "            w = optimize_voxel_weights(L_task_train, L_var_train, alpha_var=a_var)\n",
    "\n",
    "            L_task_val, L_var_val = calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, val_idx, trial_len)\n",
    "\n",
    "            fold_scores.append(objective_func(w, L_task_val, L_var_val, a_var))\n",
    "            print(f\"fold_scores: {fold_scores}\")\n",
    "            count += 1\n",
    "\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        print(mean_score)\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = (a_var)\n",
    "\n",
    "    print(\"Best parameters:\", best_params, \"with CV loss:\", best_score)\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290cb78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_var: 1.0\n",
      "k-fold num: 1\n",
      "<class 'numpy.ndarray'>\n",
      "begin\n",
      "<class 'numpy.ndarray'>\n",
      "7833600 bool 7833600\n",
      "PCA...\n",
      "L_task...\n",
      "L_var...\n",
      "(405, 405) 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 29 05:51:52 PM: Your problem has 405 variables, 1 constraints, and 0 parameters.\n",
      "(CVXPY) Sep 29 05:51:52 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Sep 29 05:51:52 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Sep 29 05:51:52 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Sep 29 05:51:52 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Sep 29 05:51:52 PM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Sep 29 05:51:52 PM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Sep 29 05:51:52 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Sep 29 05:51:52 PM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Sep 29 05:51:52 PM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Sep 29 05:51:52 PM: Applying reduction OSQP\n",
      "(CVXPY) Sep 29 05:51:52 PM: Finished problem compilation (took 2.521e-02 seconds).\n",
      "(CVXPY) Sep 29 05:51:52 PM: Invoking solver OSQP  to obtain a solution.\n",
      "(CVXPY) Sep 29 05:51:52 PM: Problem status: optimal\n",
      "(CVXPY) Sep 29 05:51:52 PM: Optimal value: 2.729e-04\n",
      "(CVXPY) Sep 29 05:51:52 PM: Compilation took 2.521e-02 seconds\n",
      "(CVXPY) Sep 29 05:51:52 PM: Solver (including time spent in interface) took 5.980e-02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing voxel weights...\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v1.0.0  -  Operator Splitting QP Solver\n",
      "              (c) The OSQP Developer Team\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 405, constraints m = 406\n",
      "          nnz(P) + nnz(A) = 83025\n",
      "settings: algebra = Built-in,\n",
      "          OSQPInt = 4 bytes, OSQPFloat = 8 bytes,\n",
      "          linear system solver = QDLDL v0.1.8,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive: 50 iterations),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25, duality gap: on),\n",
      "          time_limit: 1.00e+10 sec,\n",
      "          scaling: on (10 iterations), scaled_termination: off\n",
      "          warm starting: on, polishing: on, \n",
      "iter   objective    prim res   dual res   gap        rel kkt    rho         time\n",
      "   1   0.0000e+00   1.00e+00   6.16e+05  -6.16e+05   6.16e+05   1.00e-01    1.46e-02s\n",
      "  50   3.5605e-04   4.61e-07   1.76e-01  -7.76e-04   1.76e-01   6.43e-03*   1.90e-02s\n",
      " 200   2.8537e-04   1.93e-07   1.03e-04   2.87e-05   1.03e-04   6.43e-03    3.85e-02s\n",
      " 350   2.7295e-04   8.15e-08   3.61e-05   4.75e-06   3.61e-05   6.43e-03    5.13e-02s\n",
      "\n",
      "status:               solved\n",
      "solution polishing:   unsuccessful\n",
      "number of iterations: 350\n",
      "optimal objective:    0.0003\n",
      "dual objective:       0.0003\n",
      "duality gap:          4.7550e-06\n",
      "primal-dual integral: 6.1566e+05\n",
      "run time:             5.75e-02s\n",
      "optimal rho estimate: 3.71e-03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "begin\n",
      "<class 'numpy.ndarray'>\n",
      "7833600 bool 7833600\n",
      "PCA...\n",
      "L_task...\n",
      "L_var...\n",
      "(405, 405) 45\n",
      "Calculating objective...\n",
      "fold_scores: [np.float64(0.0004666180185896113)]\n",
      "k-fold num: 2\n",
      "<class 'numpy.ndarray'>\n",
      "begin\n",
      "<class 'numpy.ndarray'>\n",
      "7833600 bool 7833600\n",
      "PCA...\n",
      "L_task...\n",
      "L_var...\n",
      "(405, 405) 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 29 06:00:34 PM: Your problem has 405 variables, 1 constraints, and 0 parameters.\n",
      "(CVXPY) Sep 29 06:00:34 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Sep 29 06:00:34 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Sep 29 06:00:34 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Sep 29 06:00:34 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Sep 29 06:00:34 PM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Sep 29 06:00:34 PM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Sep 29 06:00:34 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Sep 29 06:00:34 PM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Sep 29 06:00:34 PM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Sep 29 06:00:34 PM: Applying reduction OSQP\n",
      "(CVXPY) Sep 29 06:00:34 PM: Finished problem compilation (took 3.563e-02 seconds).\n",
      "(CVXPY) Sep 29 06:00:34 PM: Invoking solver OSQP  to obtain a solution.\n",
      "(CVXPY) Sep 29 06:00:34 PM: Problem status: optimal\n",
      "(CVXPY) Sep 29 06:00:34 PM: Optimal value: 4.685e-04\n",
      "(CVXPY) Sep 29 06:00:34 PM: Compilation took 3.563e-02 seconds\n",
      "(CVXPY) Sep 29 06:00:34 PM: Solver (including time spent in interface) took 7.024e-02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing voxel weights...\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v1.0.0  -  Operator Splitting QP Solver\n",
      "              (c) The OSQP Developer Team\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 405, constraints m = 406\n",
      "          nnz(P) + nnz(A) = 83025\n",
      "settings: algebra = Built-in,\n",
      "          OSQPInt = 4 bytes, OSQPFloat = 8 bytes,\n",
      "          linear system solver = QDLDL v0.1.8,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive: 50 iterations),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25, duality gap: on),\n",
      "          time_limit: 1.00e+10 sec,\n",
      "          scaling: on (10 iterations), scaled_termination: off\n",
      "          warm starting: on, polishing: on, \n",
      "iter   objective    prim res   dual res   gap        rel kkt    rho         time\n",
      "   1   0.0000e+00   1.00e+00   6.34e+05  -6.34e+05   6.34e+05   1.00e-01    2.26e-02s\n",
      "  50   5.3150e-04   4.80e-07   5.24e-02  -7.73e-04   5.24e-02   6.50e-03*   2.93e-02s\n",
      " 200   4.7622e-04   1.95e-07   9.26e-05   2.09e-05   9.26e-05   6.50e-03    5.42e-02s\n",
      " 300   4.6847e-04   1.08e-07   5.09e-05   6.04e-06   5.09e-05   6.50e-03    6.13e-02s\n",
      "\n",
      "status:               solved\n",
      "solution polishing:   unsuccessful\n",
      "number of iterations: 300\n",
      "optimal objective:    0.0005\n",
      "dual objective:       0.0005\n",
      "duality gap:          6.0427e-06\n",
      "primal-dual integral: 6.3442e+05\n",
      "run time:             6.68e-02s\n",
      "optimal rho estimate: 3.27e-03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "begin\n",
      "<class 'numpy.ndarray'>\n",
      "7833600 bool 7833600\n",
      "PCA...\n",
      "L_task...\n",
      "L_var...\n",
      "(405, 405) 45\n",
      "Calculating objective...\n",
      "fold_scores: [np.float64(0.0004666180185896113), np.float64(0.00027255965467557164)]\n",
      "0.00036958883663259145\n",
      "Best parameters: 1.0 with CV loss: 0.00036958883663259145\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"alpha_var\":   [1.0]}\n",
    "\n",
    "import scipy.sparse as sp\n",
    "trial_len = 9\n",
    "best_params, best_score = calculate_weight(param_grid, beta_valume_clean_2d, bold_data, mask_2d, trial_len)\n",
    "\n",
    "# L_task, L_var, L_smooth, selected_BOLD_data = calculate_matrices(beta_valume_clean_2d, bold_data, anat_img, mask_2d, None, trial_len)\n",
    "# weights = optimize_voxel_weights(L_task, L_var, L_smooth, alpha_var=best_params[0], alpha_smooth=best_params[1])\n",
    "# weight_img, masked_weights, y = select_opt_weight(selected_BOLD_data, weights, active_low_var_voxels.astype(bool), affine)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d520c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "<class 'numpy.ndarray'>\n",
      "7833600 bool 7833600\n",
      "PCA...\n",
      "L_task...\n",
      "L_var...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m L_task, L_var \u001b[38;5;241m=\u001b[39m calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, \u001b[38;5;28;01mNone\u001b[39;00m, trial_len)\n\u001b[0;32m----> 2\u001b[0m weights \u001b[38;5;241m=\u001b[39m optimize_voxel_weights(L_task, L_var, alpha_var\u001b[38;5;241m=\u001b[39m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, alpha_smooth\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m selected_BOLD_data\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m weights\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, weights)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "L_task, L_var = calculate_matrices(beta_valume_clean_2d, bold_data, mask_2d, None, trial_len)\n",
    "weights = optimize_voxel_weights(L_task, L_var, alpha_var=best_params[0], alpha_smooth=best_params[1])\n",
    "y = selected_BOLD_data.T @ weights\n",
    "\n",
    "np.save('weights.npy', weights)\n",
    "np.save('y.npy', y)\n",
    "print(\"Finished!\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
